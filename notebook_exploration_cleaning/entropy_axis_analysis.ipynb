{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXiA65VEsgNbFjoFCyUUjT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Meguazy/project_CSD/blob/main/notebook_exploration_cleaning/entropy_axis_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "a3Tq5gupAhT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/Schnell_Traino_Project_CSD/NewData\""
      ],
      "metadata": {
        "id": "rwVhqBbNAqSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "id": "OX5SVpAxXabS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup csvs and libraries"
      ],
      "metadata": {
        "id": "W197AEh8ODR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import entropy\n",
        "from itertools import combinations\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "M7l16lOaBCC5"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change delimiter in order to open the csvs more easily"
      ],
      "metadata": {
        "id": "YBR1CMj1ZBWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_guasto_df = pd.read_csv(\"NO_GUASTO.csv\")"
      ],
      "metadata": {
        "id": "_Ynyd1WQBHE1"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "guasto_df = pd.read_csv(\"RUOTA_GUASTA.csv\")"
      ],
      "metadata": {
        "id": "T3D35Jt-BXaN"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aggregation of entries by discrete time in order not to have repeated rows"
      ],
      "metadata": {
        "id": "eVCtdKY2SJCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "guasto_df_aggregated = guasto_df.groupby('Discrete_Time').mean().reset_index()"
      ],
      "metadata": {
        "id": "eTbcE8dQJpNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_guasto_df_aggregated = no_guasto_df.groupby('Discrete_Time').mean().reset_index()"
      ],
      "metadata": {
        "id": "9CoqE5lWUYu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract accelerometer columns\n",
        "accelerometer_columns = [\n",
        "    'Board1Acc1X', 'Board1Acc1Y', 'Board1Acc1Z',\n",
        "    'Board1Acc2X', 'Board1Acc2Y', 'Board1Acc2Z',\n",
        "    'Board1Acc3X', 'Board1Acc3Y', 'Board1Acc3Z',\n",
        "    'Board2Acc1X', 'Board2Acc1Y', 'Board2Acc1Z',\n",
        "    'Board2Acc2X', 'Board2Acc2Y', 'Board2Acc2Z',\n",
        "    'Board2Acc3X', 'Board2Acc3Y', 'Board2Acc3Z',\n",
        "    'Board3Acc1X', 'Board3Acc1Y', 'Board3Acc1Z',\n",
        "    'Board3Acc2X', 'Board3Acc2Y', 'Board3Acc2Z',\n",
        "    'Board3Acc3X', 'Board3Acc3Y', 'Board3Acc3Z'\n",
        "]"
      ],
      "metadata": {
        "id": "VOM4W-3LHwyx"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistics for the columns of the anomalies dataset\n",
        "for acc_col in accelerometer_columns:\n",
        "    all_values_count = guasto_df_aggregated[acc_col].count()\n",
        "    unique_values_count = guasto_df_aggregated[acc_col].nunique()\n",
        "    unique_values_counts = guasto_df_aggregated[acc_col].value_counts()\n",
        "\n",
        "    print(f\"Statistics for {acc_col}:\")\n",
        "    print(f\"Count of all values: {all_values_count}\")\n",
        "    print(f\"Count of unique values: {unique_values_count}\")\n",
        "    print(\"Count of occurrences for each unique value:\")\n",
        "    print(unique_values_counts)\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "k0RbGZXhNbAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Valid Entropy records for each axis"
      ],
      "metadata": {
        "id": "P4iekyQHOLjd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entropy for the dataset with anomalies"
      ],
      "metadata": {
        "id": "CYVtS7yEUjFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store the count of valid entropy for each accelerometer\n",
        "valid_entropy_counts = {}\n",
        "\n",
        "# Loop through each unique Acquisition_Number\n",
        "for acquisition_number in guasto_df_aggregated['Acquisition_Number'].unique():\n",
        "    # Filter the dataframe by Acquisition_Number\n",
        "    filtered_df = guasto_df_aggregated.loc[guasto_df_aggregated['Acquisition_Number'] == acquisition_number]\n",
        "\n",
        "    # Calculate entropy for each accelerometer separately\n",
        "    for acc_col in accelerometer_columns:\n",
        "        entropy_values = []\n",
        "        valid_count = 0\n",
        "\n",
        "        entropy_values = entropy(filtered_df[acc_col])\n",
        "\n",
        "        # Check if entropy is a valid number (not -inf)\n",
        "        if not np.isinf(entropy_values):\n",
        "            valid_count = 1\n",
        "\n",
        "        # Update the count of valid entropy for the current accelerometer\n",
        "        if acc_col not in valid_entropy_counts:\n",
        "            valid_entropy_counts[acc_col] = 0\n",
        "        valid_entropy_counts[acc_col] += valid_count\n",
        "\n",
        "# Print the count of valid entropy values for each accelerometer\n",
        "print(\"Count of valid entropy values for each accelerometer:\")\n",
        "for acc_col, count in valid_entropy_counts.items():\n",
        "    print(f\"{acc_col}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KnJR80JRLVb",
        "outputId": "5f461e50-c5e7-4dc6-c8b3-5f168e17932e"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of valid entropy values for each accelerometer:\n",
            "Board1Acc1X: 23\n",
            "Board1Acc1Y: 2\n",
            "Board1Acc1Z: 38\n",
            "Board1Acc2X: 0\n",
            "Board1Acc2Y: 14\n",
            "Board1Acc2Z: 74\n",
            "Board1Acc3X: 28\n",
            "Board1Acc3Y: 0\n",
            "Board1Acc3Z: 14\n",
            "Board2Acc1X: 160\n",
            "Board2Acc1Y: 0\n",
            "Board2Acc1Z: 125\n",
            "Board2Acc2X: 0\n",
            "Board2Acc2Y: 116\n",
            "Board2Acc2Z: 90\n",
            "Board2Acc3X: 20\n",
            "Board2Acc3Y: 0\n",
            "Board2Acc3Z: 0\n",
            "Board3Acc1X: 0\n",
            "Board3Acc1Y: 33\n",
            "Board3Acc1Z: 0\n",
            "Board3Acc2X: 164\n",
            "Board3Acc2Y: 10\n",
            "Board3Acc2Z: 0\n",
            "Board3Acc3X: 145\n",
            "Board3Acc3Y: 0\n",
            "Board3Acc3Z: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entropy for the dataset with no anomalies"
      ],
      "metadata": {
        "id": "iNg4vbqSUo_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store the count of valid entropy for each accelerometer\n",
        "valid_entropy_counts = {}\n",
        "\n",
        "# Loop through each unique Acquisition_Number\n",
        "for acquisition_number in no_guasto_df_aggregated['Acquisition_Number'].unique():\n",
        "    # Filter the dataframe by Acquisition_Number\n",
        "    filtered_df = no_guasto_df_aggregated.loc[no_guasto_df_aggregated['Acquisition_Number'] == acquisition_number]\n",
        "\n",
        "    # Calculate entropy for each accelerometer separately\n",
        "    for acc_col in accelerometer_columns:\n",
        "        entropy_values = []\n",
        "        valid_count = 0\n",
        "\n",
        "        entropy_values = entropy(filtered_df[acc_col])\n",
        "\n",
        "        # Check if entropy is a valid number (not -inf)\n",
        "        if not np.isinf(entropy_values):\n",
        "            valid_count = 1\n",
        "\n",
        "        # Update the count of valid entropy for the current accelerometer\n",
        "        if acc_col not in valid_entropy_counts:\n",
        "            valid_entropy_counts[acc_col] = 0\n",
        "        valid_entropy_counts[acc_col] += valid_count\n",
        "\n",
        "# Print the count of valid entropy values for each accelerometer\n",
        "print(\"Count of valid entropy values for each accelerometer:\")\n",
        "for acc_col, count in valid_entropy_counts.items():\n",
        "    print(f\"{acc_col}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OFOnPNwUrtW",
        "outputId": "aa6584b5-e94e-4780-8d94-3df254e6bf6c"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of valid entropy values for each accelerometer:\n",
            "Board1Acc1X: 44\n",
            "Board1Acc1Y: 137\n",
            "Board1Acc1Z: 144\n",
            "Board1Acc2X: 0\n",
            "Board1Acc2Y: 128\n",
            "Board1Acc2Z: 141\n",
            "Board1Acc3X: 46\n",
            "Board1Acc3Y: 113\n",
            "Board1Acc3Z: 79\n",
            "Board2Acc1X: 162\n",
            "Board2Acc1Y: 59\n",
            "Board2Acc1Z: 146\n",
            "Board2Acc2X: 21\n",
            "Board2Acc2Y: 186\n",
            "Board2Acc2Z: 177\n",
            "Board2Acc3X: 50\n",
            "Board2Acc3Y: 44\n",
            "Board2Acc3Z: 80\n",
            "Board3Acc1X: 0\n",
            "Board3Acc1Y: 222\n",
            "Board3Acc1Z: 117\n",
            "Board3Acc2X: 170\n",
            "Board3Acc2Y: 109\n",
            "Board3Acc2Z: 39\n",
            "Board3Acc3X: 151\n",
            "Board3Acc3Y: 131\n",
            "Board3Acc3Z: 85\n"
          ]
        }
      ]
    }
  ]
}