{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Meguazy/project_CSD/blob/main/notebook_models/VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lghy3n1Gf8nP",
        "outputId": "94244cbd-9d66-4162-f6f8-690e8b3dd7fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'project_CSD'...\n",
            "remote: Enumerating objects: 599, done.\u001b[K\n",
            "remote: Counting objects: 100% (427/427), done.\u001b[K\n",
            "remote: Compressing objects: 100% (327/327), done.\u001b[K\n",
            "remote: Total 599 (delta 131), reused 359 (delta 87), pack-reused 172\u001b[K\n",
            "Receiving objects: 100% (599/599), 45.89 MiB | 15.81 MiB/s, done.\n",
            "Resolving deltas: 100% (154/154), done.\n",
            "Updating files: 100% (256/256), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://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@github.com/Meguazy/project_CSD.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd project_CSD/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYJ5QoNegF3b",
        "outputId": "f77e373e-4ea7-4f81-9afb-4a8a36a96496"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/project_CSD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Usare ogni volta che si inizia a lavorare per accertarsi che non ci siano\n",
        "#cambiamenti non sincronizzati\n",
        "\n",
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzHKX8nQgGXW",
        "outputId": "210a0200-30e4-4f7e-d58f-aa7c4f100855"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import requests\n",
        "gcloud_token = !gcloud auth print-access-token\n",
        "gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
        "EMAIL = str(gcloud_tokeninfo['email'])\n",
        "\n",
        "!echo $EMAIL\n",
        "\n",
        "#Usare per fare commit atomici e frequenti.\n",
        "#Ricordiamoci di usare mettere sempre dei messaggi di commit chiari in modo da\n",
        "#poter rollbackare o cherry-pickare in caso di bisogno.\n",
        "\n",
        "!git config --global user.email $EMAIL\n",
        "\n",
        "!git add .\n",
        "!git commit -m \"Created notebook for LSTM Autoencoder model\"\n",
        "!git push"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzIv54SCgHvC",
        "outputId": "af2b71ab-9ae5-4a0c-d9e0-e25ebb10667a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fabiomichele.devitis@studenti.unicam.it\n",
            "[main f511a96] Created notebook for LSTM Autoencoder model\n",
            " 1 file changed, 113 insertions(+)\n",
            " create mode 100644 notebook_models/LSTM_Autoencoder_Model.ipynb\n",
            "Enumerating objects: 6, done.\n",
            "Counting objects: 100% (6/6), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 1.52 KiB | 1.52 MiB/s, done.\n",
            "Total 4 (delta 1), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
            "To https://github.com/Meguazy/project_CSD.git\n",
            "   0b4955a..f511a96  main -> main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyod            # normal install\n",
        "!pip install --upgrade pyod  # or update if needed"
      ],
      "metadata": {
        "id": "bSgmmZXCx_me"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reshapeDataframe(df: pd.DataFrame, number):\n",
        "    print(\"Inizio funzione\")\n",
        "    df1 = df.iloc[:, :number]\n",
        "    for x in range(0, len(df.columns), number):\n",
        "        df1 = pd.concat([df1, df.iloc[:, x:x + number].T.reset_index(drop=True).T])\n",
        "    df1 = df1.fillna(0)\n",
        "    return df1\n"
      ],
      "metadata": {
        "id": "wi1v4n_6xujF"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from re import X\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pyod.models.vae import VAE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X1 = pd.read_csv(\"data/processed_data/Caso1SingleAxes/norm_TS1.csv\")\n",
        "X3 = pd.read_csv(\"data/processed_data/Caso1SingleAxes/norm_TS2.csv\")\n",
        "\n",
        "X2 = pd.read_csv(\"data/processed_data/Caso2SingleAxes/norm_TS1.csv\")\n",
        "X4 = pd.read_csv(\"data/processed_data/Caso2SingleAxes/norm_TS2.csv\")\n",
        "\n",
        "X_1 = X1.loc[:, X1.columns != 'Acquisition Number']\n",
        "X_2 = X2.loc[:, X2.columns != 'Acquisition Number']\n",
        "X_3 = X3.loc[:, X3.columns != 'Acquisition Number']\n",
        "X_4 = X4.loc[:, X4.columns != 'Acquisition Number']\n",
        "\n",
        "X_1 = X_1.iloc[: , :1000]\n",
        "X_2 = X_2.iloc[: , :1000]\n",
        "X_3 = X_3.iloc[: , :1000]\n",
        "X_4 = X_4.iloc[: , :1000]\n",
        "\n",
        "X_train = pd.concat([X_1, X_3], axis=0)\n",
        "X_test = pd.concat([X_2, X_4], axis=0)\n",
        "\n",
        "#X_train = reshapeDataframe(X_train, 50)\n",
        "#X_test = reshapeDataframe(X_test, 50)\n",
        "\n",
        "X_train = X_train.sample(frac = 1)\n",
        "X_test = X_test.sample(frac = 1)\n",
        "\n",
        "X_train, X_validate = train_test_split(X_train, test_size=0.2)\n",
        "\n",
        "X_train.shape, X_validate.shape, X_test.shape"
      ],
      "metadata": {
        "id": "V7e48MF2x8D4",
        "outputId": "5907b2e1-b432-45b9-932d-135cd6ab987b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((169, 1000), (43, 1000), (198, 1000))"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyod.models.vae import VAE\n",
        "clf = VAE(epochs=50, batch_size=8, dropout_rate=0.1)\n",
        "\n",
        "clf.fit(X_train)"
      ],
      "metadata": {
        "id": "f3F34AQFy2xw",
        "outputId": "fa0e4078-e0f7-453b-d6e4-b51505e6f42e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_36\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_25 (InputLayer)       [(None, 1000)]               0         []                            \n",
            "                                                                                                  \n",
            " dense_132 (Dense)           (None, 1000)                 1001000   ['input_25[0][0]']            \n",
            "                                                                                                  \n",
            " dense_133 (Dense)           (None, 128)                  128128    ['dense_132[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_72 (Dropout)        (None, 128)                  0         ['dense_133[0][0]']           \n",
            "                                                                                                  \n",
            " dense_134 (Dense)           (None, 64)                   8256      ['dropout_72[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_73 (Dropout)        (None, 64)                   0         ['dense_134[0][0]']           \n",
            "                                                                                                  \n",
            " dense_135 (Dense)           (None, 32)                   2080      ['dropout_73[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_74 (Dropout)        (None, 32)                   0         ['dense_135[0][0]']           \n",
            "                                                                                                  \n",
            " dense_136 (Dense)           (None, 2)                    66        ['dropout_74[0][0]']          \n",
            "                                                                                                  \n",
            " dense_137 (Dense)           (None, 2)                    66        ['dropout_74[0][0]']          \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)          (None, 2)                    0         ['dense_136[0][0]',           \n",
            "                                                                     'dense_137[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1139596 (4.35 MB)\n",
            "Trainable params: 1139596 (4.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_37\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_26 (InputLayer)       [(None, 2)]               0         \n",
            "                                                                 \n",
            " dense_138 (Dense)           (None, 2)                 6         \n",
            "                                                                 \n",
            " dense_139 (Dense)           (None, 32)                96        \n",
            "                                                                 \n",
            " dropout_75 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_140 (Dense)           (None, 64)                2112      \n",
            "                                                                 \n",
            " dropout_76 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_141 (Dense)           (None, 128)               8320      \n",
            "                                                                 \n",
            " dropout_77 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_142 (Dense)           (None, 1000)              129000    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 139534 (545.05 KB)\n",
            "Trainable params: 139534 (545.05 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model: \"model_38\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_25 (InputLayer)       [(None, 1000)]               0         []                            \n",
            "                                                                                                  \n",
            " model_36 (Functional)       [(None, 2),                  1139596   ['input_25[0][0]']            \n",
            "                              (None, 2),                                                          \n",
            "                              (None, 2)]                                                          \n",
            "                                                                                                  \n",
            " model_37 (Functional)       (None, 1000)                 139534    ['model_36[0][2]']            \n",
            "                                                                                                  \n",
            " dense_132 (Dense)           (None, 1000)                 1001000   ['input_25[0][0]']            \n",
            "                                                                                                  \n",
            " dense_133 (Dense)           (None, 128)                  128128    ['dense_132[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_72 (Dropout)        (None, 128)                  0         ['dense_133[0][0]']           \n",
            "                                                                                                  \n",
            " dense_134 (Dense)           (None, 64)                   8256      ['dropout_72[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_73 (Dropout)        (None, 64)                   0         ['dense_134[0][0]']           \n",
            "                                                                                                  \n",
            " dense_135 (Dense)           (None, 32)                   2080      ['dropout_73[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_74 (Dropout)        (None, 32)                   0         ['dense_135[0][0]']           \n",
            "                                                                                                  \n",
            " dense_137 (Dense)           (None, 2)                    66        ['dropout_74[0][0]']          \n",
            "                                                                                                  \n",
            " dense_136 (Dense)           (None, 2)                    66        ['dropout_74[0][0]']          \n",
            "                                                                                                  \n",
            " tf.__operators__.add_24 (T  (None, 2)                    0         ['dense_137[0][0]']           \n",
            " FOpLambda)                                                                                       \n",
            "                                                                                                  \n",
            " tf.math.square_12 (TFOpLam  (None, 2)                    0         ['dense_136[0][0]']           \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " tf.math.subtract_36 (TFOpL  (None, 2)                    0         ['tf.__operators__.add_24[0][0\n",
            " ambda)                                                             ]',                           \n",
            "                                                                     'tf.math.square_12[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.exp_12 (TFOpLambda  (None, 2)                    0         ['dense_137[0][0]']           \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.subtract_37 (TFOpL  (None, 2)                    0         ['tf.math.subtract_36[0][0]', \n",
            " ambda)                                                              'tf.math.exp_12[0][0]']      \n",
            "                                                                                                  \n",
            " tf.math.reduce_sum_12 (TFO  (None,)                      0         ['tf.math.subtract_37[0][0]'] \n",
            " pLambda)                                                                                         \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_12 (T  (None, 1000)                 0         ['model_37[0][0]']            \n",
            " FOpLambda)                                                                                       \n",
            "                                                                                                  \n",
            " tf.cast_12 (TFOpLambda)     (None, 1000)                 0         ['input_25[0][0]']            \n",
            "                                                                                                  \n",
            " tf.math.multiply_37 (TFOpL  (None,)                      0         ['tf.math.reduce_sum_12[0][0]'\n",
            " ambda)                                                             ]                             \n",
            "                                                                                                  \n",
            " tf.math.squared_difference  (None, 1000)                 0         ['tf.convert_to_tensor_12[0][0\n",
            " _12 (TFOpLambda)                                                   ]',                           \n",
            "                                                                     'tf.cast_12[0][0]']          \n",
            "                                                                                                  \n",
            " tf.math.subtract_38 (TFOpL  (None,)                      0         ['tf.math.multiply_37[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean_24 (TF  (None,)                      0         ['tf.math.squared_difference_1\n",
            " OpLambda)                                                          2[0][0]']                     \n",
            "                                                                                                  \n",
            " tf.math.abs_12 (TFOpLambda  (None,)                      0         ['tf.math.subtract_38[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.multiply_36 (TFOpL  (None,)                      0         ['tf.math.reduce_mean_24[0][0]\n",
            " ambda)                                                             ']                            \n",
            "                                                                                                  \n",
            " tf.math.multiply_38 (TFOpL  (None,)                      0         ['tf.math.abs_12[0][0]']      \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.__operators__.add_25 (T  (None,)                      0         ['tf.math.multiply_36[0][0]', \n",
            " FOpLambda)                                                          'tf.math.multiply_38[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean_25 (TF  ()                           0         ['tf.__operators__.add_25[0][0\n",
            " OpLambda)                                                          ]']                           \n",
            "                                                                                                  \n",
            " add_loss_12 (AddLoss)       ()                           0         ['tf.math.reduce_mean_25[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1279130 (4.88 MB)\n",
            "Trainable params: 1279130 (4.88 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/50\n",
            "19/19 [==============================] - 4s 31ms/step - loss: 1246.9220 - val_loss: 1083.0558\n",
            "Epoch 2/50\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 1234.7848 - val_loss: 938.4747\n",
            "Epoch 3/50\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 1050.1826 - val_loss: 921.4683\n",
            "Epoch 4/50\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 1029.8271 - val_loss: 912.6062\n",
            "Epoch 5/50\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 1018.8693 - val_loss: 911.6446\n",
            "Epoch 6/50\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 1012.4175 - val_loss: 915.1351\n",
            "Epoch 7/50\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 1011.6802 - val_loss: 914.1359\n",
            "Epoch 8/50\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 1007.5562 - val_loss: 908.6035\n",
            "Epoch 9/50\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 1008.5270 - val_loss: 917.7280\n",
            "Epoch 10/50\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 1008.5520 - val_loss: 909.8548\n",
            "Epoch 11/50\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 1010.4072 - val_loss: 910.0051\n",
            "Epoch 12/50\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 1008.0093 - val_loss: 910.6017\n",
            "Epoch 13/50\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 1007.5673 - val_loss: 911.2028\n",
            "Epoch 14/50\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 1008.1970 - val_loss: 910.5335\n",
            "Epoch 15/50\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 1008.3242 - val_loss: 911.3093\n",
            "Epoch 16/50\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 1007.2967 - val_loss: 915.4265\n",
            "Epoch 17/50\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 1008.7090 - val_loss: 917.7080\n",
            "Epoch 18/50\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 1007.0599 - val_loss: 911.5656\n",
            "Epoch 19/50\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 1010.2914 - val_loss: 910.3207\n",
            "Epoch 20/50\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 1007.3325 - val_loss: 926.0955\n",
            "Epoch 21/50\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 1008.7794 - val_loss: 916.4213\n",
            "Epoch 22/50\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 1010.1602 - val_loss: 911.9587\n",
            "Epoch 23/50\n",
            "19/19 [==============================] - 0s 24ms/step - loss: 1009.6924 - val_loss: 913.7119\n",
            "Epoch 24/50\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 1005.7170 - val_loss: 913.1015\n",
            "Epoch 25/50\n",
            "19/19 [==============================] - 0s 24ms/step - loss: 1006.5676 - val_loss: 914.0694\n",
            "Epoch 26/50\n",
            "19/19 [==============================] - 0s 24ms/step - loss: 1008.2269 - val_loss: 912.0245\n",
            "Epoch 27/50\n",
            "19/19 [==============================] - 0s 26ms/step - loss: 1011.3364 - val_loss: 915.6343\n",
            "Epoch 28/50\n",
            "19/19 [==============================] - 0s 26ms/step - loss: 1007.3532 - val_loss: 910.7224\n",
            "Epoch 29/50\n",
            "19/19 [==============================] - 0s 24ms/step - loss: 1008.5843 - val_loss: 910.1180\n",
            "Epoch 30/50\n",
            "19/19 [==============================] - 0s 25ms/step - loss: 1010.3766 - val_loss: 910.8812\n",
            "Epoch 31/50\n",
            "19/19 [==============================] - 0s 25ms/step - loss: 1010.5532 - val_loss: 912.6566\n",
            "Epoch 32/50\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 1007.3374 - val_loss: 923.1691\n",
            "Epoch 33/50\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 1007.1522 - val_loss: 912.9041\n",
            "Epoch 34/50\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 1009.0891 - val_loss: 914.0726\n",
            "Epoch 35/50\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 1006.2994 - val_loss: 913.9946\n",
            "Epoch 36/50\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 1006.8950 - val_loss: 911.5640\n",
            "Epoch 37/50\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 1006.8732 - val_loss: 913.3061\n",
            "Epoch 38/50\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 1006.8081 - val_loss: 915.1318\n",
            "Epoch 39/50\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 1006.8170 - val_loss: 916.4465\n",
            "Epoch 40/50\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 1008.6545 - val_loss: 911.8591\n",
            "Epoch 41/50\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 1006.5383 - val_loss: 932.9280\n",
            "Epoch 42/50\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 1002.8606 - val_loss: 912.7017\n",
            "Epoch 43/50\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 1005.8875 - val_loss: 916.0528\n",
            "Epoch 44/50\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 1004.0190 - val_loss: 914.3999\n",
            "Epoch 45/50\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 1006.2512 - val_loss: 916.2271\n",
            "Epoch 46/50\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 1008.3666 - val_loss: 912.5437\n",
            "Epoch 47/50\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 1005.7043 - val_loss: 913.5451\n",
            "Epoch 48/50\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 1008.4988 - val_loss: 912.3924\n",
            "Epoch 49/50\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 1008.7845 - val_loss: 914.9763\n",
            "Epoch 50/50\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 1008.5324 - val_loss: 911.5166\n",
            "6/6 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VAE(batch_size=8, capacity=0.0, contamination=0.1,\n",
              "  decoder_neurons=[32, 64, 128], dropout_rate=0.1,\n",
              "  encoder_neurons=[128, 64, 32], epochs=50, gamma=1.0,\n",
              "  hidden_activation='relu', l2_regularizer=0.1, latent_dim=2,\n",
              "  loss=<function mean_squared_error at 0x781db2bdcee0>, optimizer='adam',\n",
              "  output_activation='sigmoid', preprocessing=True, random_state=None,\n",
              "  validation_size=0.1, verbose=1)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = clf.predict(X_test)\n",
        "#import matplotlib.pyplot as plt\n",
        "#plt.plot(np.arange(1,b.size+1),b)\n",
        "print(f\"---------CASO 2----------\")\n",
        "print(f\"Percentuale di time series anomale: {np.count_nonzero(b == 1)/len(b)*100}%\")\n",
        "\n",
        "c = clf.predict(X_validate)\n",
        "#import matplotlib.pyplot as plt\n",
        "#plt.plot(np.arange(1,a.size+1),a)\n",
        "print(f\"---------CASO 1 (validate)----------\")\n",
        "print(f\"Percentuale di time series anomale: {np.count_nonzero(c == 1)/len(c)*100}%\")"
      ],
      "metadata": {
        "id": "rVw37ge6j6S_",
        "outputId": "4e8f8c42-8771-4418-8437-ed1085d9cfc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 4ms/step\n",
            "---------CASO 2----------\n",
            "Percentuale di time series anomale: 23.232323232323232%\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "---------CASO 1 (validate)----------\n",
            "Percentuale di time series anomale: 16.27906976744186%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the outlier scores for the train data\n",
        "y_train_scores = clf.decision_scores_\n",
        "# Predict the anomaly scores\n",
        "y_test_scores = clf.decision_function(X_test)  # outlier scores\n",
        "#y_test_scores = clf.decision_function(X_2)  # outlier scores\n",
        "y_test_scores = pd.Series(y_test_scores)\n",
        "\n",
        "# Plot it!\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(y_test_scores, bins=\"auto\")\n",
        "plt.title(\"Histogram for Model Clf1 Anomaly Scores\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xmICB_yry9B8",
        "outputId": "1f646dd1-de7d-4013-e1c5-f65ab830c4c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiUAAAGzCAYAAADwumcoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA0QklEQVR4nO3deVwW5f7/8fetyA3KFgqiibhkbqWVppL7UmhmmpJbmZrtaKllSZ1SWg6WldXJLOukVpit5ilzT+2cUnP9WVYkhmkpaBagELhw/f7owf31FlDQG7i8eT0fj3koM9fMfK5Z4M3cM4PDGGMEAABQwapUdAEAAAASoQQAAFiCUAIAAKxAKAEAAFYglAAAACsQSgAAgBUIJQAAwAqEEgAAYAVCCQAAsAKhpJJq0KCBRo0aVdFlnJeOHz+uBx98UJGRkapSpYoGDBhQ0SWViblz58rhcGj37t2lnnfq1KlyOBwerWf37t1yOByaO3eu2/ilS5fqsssuk5+fnxwOhzIyMjy6Xm92LvsYKAuEEi9Q8I1l06ZNRU7v1q2bLrnkknNez+eff66pU6ee83LOd2+++aamT5+u2NhYzZs3TxMmTCjT9XXr1k0Oh0NNmjQpcvqKFSvkcDjkcDj04YcflmktZWXNmjUaOHCgIiIi5Ovrq/DwcPXr108ff/zxaec7dOiQBg8eLH9/f82cOVNvv/22atSooeTkZE2YMEFXXXWVK6yc7Q/edu3ayeFwaNasWWc1f2Xz6aefqmvXrgoPD1f16tXVqFEjDR48WEuXLq3o0nAeIJRUUsnJyXr99ddLNc/nn3+uhISEMqro/PHFF1/owgsv1IwZMzRixAh17dq1zNfp5+enlJQUffPNN4WmJSUlyc/Pr8xrKCtTpkxR9+7d9d133+nOO+/Uq6++qkmTJunIkSMaNGiQ5s+fX+y8Gzdu1OHDh/XEE09ozJgxuvnmm1WtWjWtW7dOL730kg4fPqzmzZufdW07d+7Uxo0b1aBBAyUlJZ31ciqLZ599Vtdff70cDofi4+M1Y8YMDRo0SDt37tSCBQsqujycB3wqugBUDKfTWdEllFp2drZq1KhR0WXowIEDCgkJ8djy8vPzdfTo0dMGi8aNG+v48eN699131a5dO9f43NxcLVy4UH379tVHH33ksZrKy4cffqjHH39csbGxmj9/vqpVq+aaNmnSJC1btkzHjh0rdv4DBw5IUqH9cf311ysjI0OBgYF69tlntW3btrOq75133lF4eLiee+45xcbGavfu3WrQoMFZLcvbHT9+XE888YSuvvpqLV++vND0gn1VHkpyTsFOXCmppE69p+TYsWNKSEhQkyZN5Ofnp5o1a6pTp05asWKFJGnUqFGaOXOmJLk+Kjj5noHs7Gzdf//9ioyMlNPpVNOmTfXss8/q1D9C/ddff+nee+9VrVq1FBgYqOuvv16//fabHA6H20dDBfckfP/99xo+fLguuOACderUSZK0fft2jRo1So0aNZKfn58iIiJ066236tChQ27rKljGTz/9pJtvvlnBwcEKCwvTo48+KmOM9u7dq/79+ysoKEgRERF67rnnTrvNCu5pWL16tXbs2OHaBmvWrCnVNnA4HBo7dqySkpLUsmVLOZ3OEl3aHjZsmN577z3l5+e7xn366afKycnR4MGDi5xn69at6tOnj4KCghQQEKCePXtq/fr1hdrt2LFDPXr0kL+/v+rVq6cnn3zSbT0nW7JkiTp37qwaNWooMDBQffv21Y4dO85Yf1EeffRRhYaG6s0333QLJAViYmJ03XXXFTlvt27dNHLkSEnSlVdeKYfD4TqmQ0NDFRgYeFY1nWz+/PmKjY3Vddddp+Dg4CKv2hQcZykpKRo1apRCQkIUHBys0aNHKycnx61twQ/uxo0by+l0qkGDBnr44YeVl5fn1q5Bgwa67rrrtGbNGrVt21b+/v669NJLXcfaxx9/rEsvvVR+fn5q06aNtm7d6jZ/Sc+RU40cOVK1atUqMghec801atq0abHz/v7778rKylLHjh2LnB4eHu72dW5urqZOnaqLL75Yfn5+qlOnjgYOHKhdu3a52njinPrtt9906623qnbt2nI6nWrZsqXefPPNQvX961//UsuWLVW9enVdcMEFatu27Wmv0qFscKXEi2RmZur3338vNP50v2kWmDp1qhITE3XbbbepXbt2ysrK0qZNm7RlyxZdffXVuvPOO7Vv3z6tWLFCb7/9ttu8xhhdf/31Wr16tcaMGaPLLrtMy5Yt06RJk/Tbb79pxowZrrajRo3S+++/rxEjRqhDhw5au3at+vbtW2xdN954o5o0aaJ//vOfrm9EK1as0M8//6zRo0crIiJCO3bs0OzZs7Vjxw6tX7++0A2WQ4YMUfPmzTVt2jQtXrxYTz75pEJDQ/Xaa6+pR48eevrpp5WUlKQHHnhAV155pbp06VJkLWFhYXr77bf11FNP6ciRI0pMTJQkNW/evFTbQPr7I6D3339fY8eOVa1atUr02/fw4cM1depUrVmzRj169JD09w/Nnj17FvqGL/0dNDp37qygoCA9+OCDqlatml577TV169ZNa9euVfv27SVJaWlp6t69u44fP67JkyerRo0amj17tvz9/Qst8+2339bIkSMVExOjp59+Wjk5OZo1a5Y6deqkrVu3luoqws6dO/Xjjz/q1ltvPasA8cgjj6hp06aaPXu2Hn/8cTVs2FCNGzcu9XKKs2HDBqWkpGjOnDny9fXVwIEDlZSUpIcffrjI9oMHD1bDhg2VmJioLVu26I033lB4eLiefvppV5vbbrtN8+bNU2xsrO6//35t2LBBiYmJ+uGHH7Rw4UK35aWkpGj48OG68847dfPNN+vZZ59Vv3799Oqrr+rhhx/WPffcI0lKTEzU4MGDlZycrCpV/v49s7TnSIERI0borbfe0rJly9zCYFpamr744gtNmTKl2O0VHh4uf39/ffrppxo3bpxCQ0OLbXvixAldd911WrVqlYYOHar77rtPhw8f1ooVK/Tdd9+pcePGHjmn0tPT1aFDB1doCQsL05IlSzRmzBhlZWVp/PjxkqTXX39d9957r2JjY3XfffcpNzdX27dv14YNGzR8+PBi+4EyYHDemzNnjpF02qFly5Zu80RFRZmRI0e6vm7durXp27fvadcTFxdnijpkPvnkEyPJPPnkk27jY2NjjcPhMCkpKcYYYzZv3mwkmfHjx7u1GzVqlJFkpkyZ4ho3ZcoUI8kMGzas0PpycnIKjXv33XeNJPPll18WWsYdd9zhGnf8+HFTr14943A4zLRp01zj//zzT+Pv7++2TYrTtWvXQtuzpNvAGGMkmSpVqpgdO3accV2nrq9t27ZmzJgxrpp9fX3NvHnzzOrVq40k88EHH7jmGzBggPH19TW7du1yjdu3b58JDAw0Xbp0cY0bP368kWQ2bNjgGnfgwAETHBxsJJnU1FRjjDGHDx82ISEh5vbbb3erLy0tzQQHB7uNL9j2p7No0SIjycyYMaNE2yE1NdVIMnPmzHGNKzj2N27cWOx806dPd+tHSY0dO9ZERkaa/Px8Y4wxy5cvN5LM1q1b3doV9PXWW291G3/DDTeYmjVrur7etm2bkWRuu+02t3YPPPCAkWS++OIL17ioqCgjyXz99deuccuWLTOSjL+/v/nll19c41977TUjyaxevdo1rqTnSMH2K9g2J06cMPXq1TNDhgxxm/f55583DofD/Pzzz0VtKpfHHnvMSDI1atQwffr0MU899ZTZvHlzoXZvvvmmkWSef/75QtMKtrcnzqkxY8aYOnXqmN9//91t/NChQ01wcLBrO/Xv37/QOY2Kwcc3XmTmzJlasWJFoaFVq1ZnnDckJEQ7duzQzp07S73ezz//XFWrVtW9997rNv7++++XMUZLliyRJNfl1ILf8AqMGzeu2GXfddddhcad/Bt8bm6ufv/9d3Xo0EGStGXLlkLtb7vtNtf/q1atqrZt28oYozFjxrjGh4SEqGnTpvr555+LreV0SroNCnTt2lUtWrQo9XqGDx+ujz/+WEePHtWHH36oqlWr6oYbbijU7sSJE1q+fLkGDBigRo0aucbXqVNHw4cP1//+9z9lZWW5au/QoYPbvSphYWG66aab3Ja5YsUKZWRkaNiwYfr9999dQ9WqVdW+fXutXr26VH0pWL8nPmbxtOPHj+u9997TkCFDXFcVevToofDw8GJveD31WO3cubMOHTrktp0laeLEiW7t7r//fknS4sWL3ca3aNFC0dHRrq8Lrmz16NFD9evXLzT+5GO3tOdIgSpVquimm27Sf/7zHx0+fNg1PikpSVdddZUaNmxY7LySlJCQoPnz5+vyyy/XsmXL9Mgjj6hNmza64oor9MMPP7jaffTRR6pVq1aR537B9j7Xc8oYo48++kj9+vWTMcbtmI2JiVFmZqZrW4SEhOjXX3/Vxo0bT9s/lD1CiRdp166devXqVWi44IILzjjv448/royMDF188cW69NJLNWnSJG3fvr1E6/3ll19Ut27dQj9cCp56+OWXX1z/VqlSpdA3tosuuqjYZRf1TfCPP/7Qfffdp9q1a8vf319hYWGudpmZmYXan/wNXJKCg4Pl5+enWrVqFRr/559/FlvL6ZR0GxQ40zf34gwdOlSZmZlasmSJkpKSdN111xX5Q/3gwYPKyckp8h6A5s2bKz8/X3v37nXVVtTjxqfOWxBYe/ToobCwMLdh+fLlpb6RMSgoSJLcfvjZYvny5Tp48KDatWunlJQUpaSkKDU1Vd27d9e7775b5P02px5nBeddwTFVcPyferxHREQoJCSk0DFS1HErSZGRkUWOP/nYLe05crJbbrlFf/31l+vjpOTkZG3evFkjRow47XwFhg0bpv/+97/6888/tXz5cg0fPlxbt25Vv379lJubK0natWuXmjZtKh+f4u8gONdz6uDBg8rIyNDs2bMLHa+jR4+W9H833z700EMKCAhQu3bt1KRJE8XFxemrr74qUX/hWdxTAklSly5dtGvXLi1atEjLly/XG2+8oRkzZujVV191u9JQ3oq6r2Hw4MH6+uuvNWnSJF122WUKCAhQfn6+evfuXeQPi6pVq5ZonKRCN9CVlaL6VRJ16tRRt27d9Nxzz+mrr74q1yduCrbt22+/rYiIiELTT/cDpijNmjWTJH377bfnXpyHFVwNKe4G4rVr16p79+5u40p6TJX0pXLFLa8k6yntOXKyFi1aqE2bNnrnnXd0yy236J133pGvr2+x26I4QUFBuvrqq3X11VerWrVqmjdvnjZs2FBmj9Cfek4V9PPmm2923RB9qoKryM2bN1dycrI+++wzLV26VB999JFeeeUVPfbYY7wGoZwRSuASGhqq0aNHa/To0Tpy5Ii6dOmiqVOnukJJcd9Mo6KitHLlSh0+fNjtt5off/zRNb3g3/z8fKWmprr9Zp6SklLiGv/880+tWrVKCQkJeuyxx1zjz+ZjJ08q6TbwhOHDh+u2225TSEiIrr322iLbhIWFqXr16kpOTi407ccff1SVKlVcv3FHRUUVuf1OnbfgJtLw8HD16tXrXLuhiy++WE2bNtWiRYv04osvKiAg4JyX6QnZ2dlatGiRhgwZotjY2ELT7733XiUlJRUKJWdScPzv3LnT7d0p6enpysjI8Ngx4olz5JZbbtHEiRO1f/9+zZ8/X3379i3RFdfitG3bVvPmzdP+/fsl/X0sbdiwQceOHSvyqSvp3M+psLAwBQYG6sSJEyU6XmvUqKEhQ4ZoyJAhOnr0qAYOHKinnnpK8fHxPFpcjvj4BpJU6FHBgIAAXXTRRW6PKha8I+TU13hfe+21OnHihF5++WW38TNmzJDD4VCfPn0k/f14pyS98sorbu3+9a9/lbjOgt8ST/3t84UXXijxMspCSbeBJ8TGxmrKlCl65ZVX5OvrW2SbqlWr6pprrtGiRYvc3mSanp6u+fPnq1OnTq6PT6699lqtX7/e7cVsBw8eLHTvRExMjIKCgvTPf/6zyCe6Dh48WOq+JCQk6NChQ7rtttt0/PjxQtOXL1+uzz77rNTLPRcLFy5Udna24uLiFBsbW2i47rrr9NFHHxV6jPdMCgLkqcfq888/L0mnfQqtNDxxjgwbNkwOh0P33Xeffv75Z918881nnCcnJ0fr1q0rclrB/R8FHwkOGjRIv//+e6Hz5eS6z/Wcqlq1qgYNGqSPPvpI3333XaHpJx+vp37/8/X1VYsWLWSMKdHTi/AcrpRA0t+XbLt166Y2bdooNDRUmzZt0ocffqixY8e62rRp00bS378pxsTEqGrVqho6dKj69eun7t2765FHHtHu3bvVunVrLV++XIsWLdL48eNdv2G3adNGgwYN0gsvvKBDhw65Hgn+6aefJJXssnZQUJC6dOmiZ555RseOHdOFF16o5cuXKzU1tQy2SsmVdBt4QnBwcIle9//kk09qxYoV6tSpk+655x75+PjotddeU15enp555hlXuwcffFBvv/22evfurfvuu8/1SHBUVJTbfUVBQUGaNWuWRowYoSuuuEJDhw5VWFiY9uzZo8WLF6tjx45F/pA5nSFDhujbb7/VU089pa1bt2rYsGGKiorSoUOHtHTpUq1ateqs3hWRmZnpCrsF9wa8/PLLCgkJUUhIiNtxfaqkpCTVrFlTV111VZHTr7/+er3++utavHixBg4cWOKaWrdurZEjR2r27NnKyMhQ165d9c0332jevHkaMGBAqa+8FMcT50hYWJh69+6tDz74QCEhISUKTDk5ObrqqqvUoUMH9e7dW5GRkcrIyNAnn3yi//73vxowYIAuv/xySX9fiXnrrbc0ceJEffPNN+rcubOys7O1cuVK3XPPPerfv79Hzqlp06Zp9erVat++vW6//Xa1aNFCf/zxh7Zs2aKVK1fqjz/+kPT3O1giIiLUsWNH1a5dWz/88INefvll9e3b18obsb1ahTzzA48602ORRT3CeuojwU8++aRp166dCQkJMf7+/qZZs2bmqaeeMkePHnW1OX78uBk3bpwJCwszDofD7ZHPw4cPmwkTJpi6deuaatWqmSZNmpjp06e7Hu8rkJ2dbeLi4kxoaKgJCAgwAwYMMMnJyUaS2yO6BY9ZHjx4sFB/fv31V3PDDTeYkJAQExwcbG688Uazb9++Yh8rPnUZI0eONDVq1CjRdipKce1Kug0kmbi4uDOupzR1FfVIsDHGbNmyxcTExJiAgABTvXp10717d7fHTAts377ddO3a1fj5+ZkLL7zQPPHEE+bf//53kY/Srl692sTExJjg4GDj5+dnGjdubEaNGmU2bdrkalOSR4JPtmrVKtO/f38THh5ufHx8TFhYmOnXr59ZtGiRq01pHgkuaFvUEBUVVWwd6enpxsfHx4wYMaLYNjk5OaZ69ermhhtucOvrqcfZqY/bGmPMsWPHTEJCgmnYsKGpVq2aiYyMNPHx8SY3N9dt3qioqCIf0S/q2Cno6/Tp013jSnqOFFVjgffff7/QI/Wnc+zYMfP666+bAQMGmKioKON0Ok316tXN5ZdfbqZPn27y8vLc2ufk5JhHHnnEtS0iIiJMbGys2yPsnjin0tPTTVxcnImMjHStp2fPnmb27NmuNq+99prp0qWLqVmzpnE6naZx48Zm0qRJJjMzs0R9h+c4jCmnO/uAYmzbtk2XX3653nnnnUKPoQKoGIsWLdKAAQP05ZdfqnPnzhVdDioJ7ilBufrrr78KjXvhhRdUpUqVYt+kCqD8vf7662rUqJHrzzsA5YF7SlCunnnmGW3evFndu3eXj4+PlixZoiVLluiOO+4o9P4FAOVvwYIF2r59uxYvXqwXX3yxxI8wA57AxzcoVytWrFBCQoK+//57HTlyRPXr19eIESP0yCOPlPo9FwA8z+FwKCAgQEOGDNGrr77KeYlyRSgBAABW4J4SAABgBUIJAACwgnUfFubn52vfvn0KDAzkBisAAM4TxhgdPnxYdevWVZUqZ3fNw7pQsm/fPp7CAADgPLV3717Vq1fvrOa1LpQUvNJ37969rr/NAQAA7JaVlaXIyMhzejW/daGk4COboKAgQgkAAOeZc7n1ghtdAQCAFQglAADACoQSAABgBUIJAACwAqEEAABYgVACAACsQCgBAABWIJQAAAArEEoAAIAVCCUAAMAKhBIAAGAFQgkAALACoQQAAFiBUAIAAKzgU9EFoHw0mLz4jG12T+tbDpUAAFA0rpQAAAArEEoAAIAVCCUAAMAKhBIAAGAFQgkAALACoQQAAFiBUAIAAKxAKAEAAFYglAAAACsQSgAAgBUIJQAAwAqEEgAAYAVCCQAAsAKhBAAAWIFQAgAArEAoAQAAViCUAAAAKxBKAACAFQglAADACoQSAABgBUIJAACwAqEEAABYgVACAACsQCgBAABWIJQAAAArEEoAAIAVCCUAAMAKpQols2bNUqtWrRQUFKSgoCBFR0dryZIlrum5ubmKi4tTzZo1FRAQoEGDBik9Pd3jRQMAAO9TqlBSr149TZs2TZs3b9amTZvUo0cP9e/fXzt27JAkTZgwQZ9++qk++OADrV27Vvv27dPAgQPLpHAAAOBdHMYYcy4LCA0N1fTp0xUbG6uwsDDNnz9fsbGxkqQff/xRzZs317p169ShQ4cSLS8rK0vBwcHKzMxUUFDQuZSGkzSYvPiMbXZP61sOlQAAvJEnfn6f9T0lJ06c0IIFC5Sdna3o6Ght3rxZx44dU69evVxtmjVrpvr162vdunXFLicvL09ZWVluAwAAqHx8SjvDt99+q+joaOXm5iogIEALFy5UixYttG3bNvn6+iokJMStfe3atZWWllbs8hITE5WQkFDqwiuLklzhAADAG5T6SknTpk21bds2bdiwQXfffbdGjhyp77///qwLiI+PV2ZmpmvYu3fvWS8LAACcv0p9pcTX11cXXXSRJKlNmzbauHGjXnzxRQ0ZMkRHjx5VRkaG29WS9PR0RUREFLs8p9Mpp9NZ+soBAIBXOef3lOTn5ysvL09t2rRRtWrVtGrVKte05ORk7dmzR9HR0ee6GgAA4OVKdaUkPj5effr0Uf369XX48GHNnz9fa9as0bJlyxQcHKwxY8Zo4sSJCg0NVVBQkMaNG6fo6OgSP3kDAAAqr1KFkgMHDuiWW27R/v37FRwcrFatWmnZsmW6+uqrJUkzZsxQlSpVNGjQIOXl5SkmJkavvPJKmRQOAAC8yzm/p8TTeE+Ju/J8+ob3lAAAzlaFvqcEAADAkwglAADACoQSAABgBUIJAACwAqEEAABYgVACAACsQCgBAABWIJQAAAArEEoAAIAVCCUAAMAKhBIAAGAFQgkAALACoQQAAFiBUAIAAKxAKAEAAFYglAAAACsQSgAAgBUIJQAAwAqEEgAAYAVCCQAAsAKhBAAAWIFQAgAArEAoAQAAViCUAAAAKxBKAACAFQglAADACoQSAABgBUIJAACwAqEEAABYgVACAACsQCgBAABWIJQAAAArEEoAAIAVCCUAAMAKhBIAAGAFQgkAALACoQQAAFiBUAIAAKxAKAEAAFYglAAAACsQSgAAgBUIJQAAwAqEEgAAYIVShZLExERdeeWVCgwMVHh4uAYMGKDk5GS3Nt26dZPD4XAb7rrrLo8WDQAAvE+pQsnatWsVFxen9evXa8WKFTp27JiuueYaZWdnu7W7/fbbtX//ftfwzDPPeLRoAADgfXxK03jp0qVuX8+dO1fh4eHavHmzunTp4hpfvXp1RUREeKZCAABQKZzTPSWZmZmSpNDQULfxSUlJqlWrli655BLFx8crJyen2GXk5eUpKyvLbQAAAJVPqa6UnCw/P1/jx49Xx44ddckll7jGDx8+XFFRUapbt662b9+uhx56SMnJyfr444+LXE5iYqISEhLOtgwAAOAlHMYYczYz3n333VqyZIn+97//qV69esW2++KLL9SzZ0+lpKSocePGhabn5eUpLy/P9XVWVpYiIyOVmZmpoKCgsynNqzSYvLjc1rV7Wt9yWxcAwLtkZWUpODj4nH5+n9WVkrFjx+qzzz7Tl19+edpAIknt27eXpGJDidPplNPpPJsyAACAFylVKDHGaNy4cVq4cKHWrFmjhg0bnnGebdu2SZLq1KlzVgUCAIDKoVShJC4uTvPnz9eiRYsUGBiotLQ0SVJwcLD8/f21a9cuzZ8/X9dee61q1qyp7du3a8KECerSpYtatWpVJh0AAADeoVShZNasWZL+fkHayebMmaNRo0bJ19dXK1eu1AsvvKDs7GxFRkZq0KBB+sc//uGxggEAgHcq9cc3pxMZGam1a9eeU0EAAKBy4m/fAAAAKxBKAACAFQglAADACoQSAABgBUIJAACwAqEEAABYgVACAACsQCgBAABWIJQAAAArEEoAAIAVCCUAAMAKhBIAAGAFQgkAALACoQQAAFiBUAIAAKxAKAEAAFYglAAAACsQSgAAgBUIJQAAwAqEEgAAYAVCCQAAsAKhBAAAWIFQAgAArEAoAQAAViCUAAAAKxBKAACAFQglAADACoQSAABgBUIJAACwAqEEAABYgVACAACsQCgBAABWIJQAAAArEEoAAIAVCCUAAMAKhBIAAGAFQgkAALACoQQAAFiBUAIAAKxAKAEAAFYglAAAACsQSgAAgBVKFUoSExN15ZVXKjAwUOHh4RowYICSk5Pd2uTm5iouLk41a9ZUQECABg0apPT0dI8WDQAAvE+pQsnatWsVFxen9evXa8WKFTp27JiuueYaZWdnu9pMmDBBn376qT744AOtXbtW+/bt08CBAz1eOAAA8C4+pWm8dOlSt6/nzp2r8PBwbd68WV26dFFmZqb+/e9/a/78+erRo4ckac6cOWrevLnWr1+vDh06eK5yAADgVc7pnpLMzExJUmhoqCRp8+bNOnbsmHr16uVq06xZM9WvX1/r1q0rchl5eXnKyspyGwAAQOVTqislJ8vPz9f48ePVsWNHXXLJJZKktLQ0+fr6KiQkxK1t7dq1lZaWVuRyEhMTlZCQcLZlnNcaTF5c0SUAAGCNs75SEhcXp++++04LFiw4pwLi4+OVmZnpGvbu3XtOywMAAOens7pSMnbsWH322Wf68ssvVa9ePdf4iIgIHT16VBkZGW5XS9LT0xUREVHkspxOp5xO59mUAQAAvEiprpQYYzR27FgtXLhQX3zxhRo2bOg2vU2bNqpWrZpWrVrlGpecnKw9e/YoOjraMxUDAACvVKorJXFxcZo/f74WLVqkwMBA130iwcHB8vf3V3BwsMaMGaOJEycqNDRUQUFBGjdunKKjo3nyBgAAnFapQsmsWbMkSd26dXMbP2fOHI0aNUqSNGPGDFWpUkWDBg1SXl6eYmJi9Morr3ikWAAA4L1KFUqMMWds4+fnp5kzZ2rmzJlnXRQAAKh8+Ns3AADACoQSAABgBUIJAACwAqEEAABYgVACAACsQCgBAABWIJQAAAArEEoAAIAVCCUAAMAKhBIAAGAFQgkAALACoQQAAFiBUAIAAKxAKAEAAFYglAAAACsQSgAAgBUIJQAAwAqEEgAAYAVCCQAAsAKhBAAAWIFQAgAArEAoAQAAViCUAAAAKxBKAACAFQglAADACoQSAABgBUIJAACwAqEEAABYgVACAACsQCgBAABWIJQAAAArEEoAAIAVCCUAAMAKhBIAAGAFQgkAALACoQQAAFjBp6IL8FYNJi+u6BIAADivcKUEAABYgVACAACsQCgBAABWIJQAAAArEEoAAIAVSh1KvvzyS/Xr109169aVw+HQJ5984jZ91KhRcjgcbkPv3r09VS8AAPBSpQ4l2dnZat26tWbOnFlsm969e2v//v2u4d133z2nIgEAgPcr9XtK+vTpoz59+py2jdPpVERExFkXBQAAKp8yuadkzZo1Cg8PV9OmTXX33Xfr0KFDxbbNy8tTVlaW2wAAACofj4eS3r1766233tKqVav09NNPa+3aterTp49OnDhRZPvExEQFBwe7hsjISE+XBAAAzgMef8380KFDXf+/9NJL1apVKzVu3Fhr1qxRz549C7WPj4/XxIkTXV9nZWURTAAAqITK/JHgRo0aqVatWkpJSSlyutPpVFBQkNsAAAAqnzIPJb/++qsOHTqkOnXqlPWqAADAeazUH98cOXLE7apHamqqtm3bptDQUIWGhiohIUGDBg1SRESEdu3apQcffFAXXXSRYmJiPFo4AADwLqUOJZs2bVL37t1dXxfcDzJy5EjNmjVL27dv17x585SRkaG6devqmmuu0RNPPCGn0+m5qgEAgNcpdSjp1q2bjDHFTl+2bNk5FQQAACon/vYNAACwAqEEAABYgVACAACsQCgBAABW8PgbXSuLBpMXV3QJAAB4Fa6UAAAAKxBKAACAFQglAADACoQSAABgBUIJAACwAqEEAABYgVACAACsQCgBAABWIJQAAAArEEoAAIAVeM08XM706vzd0/qWUyUAgMqIKyUAAMAKhBIAAGAFQgkAALACoQQAAFiBUAIAAKxAKAEAAFYglAAAACsQSgAAgBUIJQAAwAqEEgAAYAVCCQAAsAKhBAAAWIFQAgAArEAoAQAAViCUAAAAKxBKAACAFQglAADACoQSAABgBUIJAACwAqEEAABYgVACAACsQCgBAABWIJQAAAArEEoAAIAVCCUAAMAKhBIAAGAFQgkAALBCqUPJl19+qX79+qlu3bpyOBz65JNP3KYbY/TYY4+pTp068vf3V69evbRz505P1QsAALxUqUNJdna2WrdurZkzZxY5/ZlnntFLL72kV199VRs2bFCNGjUUExOj3Nzccy4WAAB4L5/SztCnTx/16dOnyGnGGL3wwgv6xz/+of79+0uS3nrrLdWuXVuffPKJhg4dem7VAgAAr+XRe0pSU1OVlpamXr16ucYFBwerffv2WrduXZHz5OXlKSsry20AAACVj0dDSVpamiSpdu3abuNr167tmnaqxMREBQcHu4bIyEhPlgQAAM4TFf70TXx8vDIzM13D3r17K7okAABQATwaSiIiIiRJ6enpbuPT09Nd007ldDoVFBTkNgAAgMrHo6GkYcOGioiI0KpVq1zjsrKytGHDBkVHR3tyVQAAwMuU+umbI0eOKCUlxfV1amqqtm3bptDQUNWvX1/jx4/Xk08+qSZNmqhhw4Z69NFHVbduXQ0YMMCTdQMAAC9T6lCyadMmde/e3fX1xIkTJUkjR47U3Llz9eCDDyo7O1t33HGHMjIy1KlTJy1dulR+fn6eqxoAAHgdhzHGVHQRJ8vKylJwcLAyMzOtvr+kweTFFV1Cuds9rW9FlwAAsJQnfn5X+NM3AAAAEqEEAABYglACAACsQCgBAABWIJQAAAArEEoAAIAVCCUAAMAKhBIAAGAFQgkAALACoQQAAFiBUAIAAKxAKAEAAFYglAAAACsQSgAAgBUIJQAAwAqEEgAAYAVCCQAAsAKhBAAAWIFQAgAArEAoAQAAViCUAAAAKxBKAACAFQglAADACoQSAABgBUIJAACwAqEEAABYgVACAACsQCgBAABWIJQAAAArEEoAAIAVCCUAAMAKhBIAAGAFQgkAALACoQQAAFiBUAIAAKzgU9EFlLcGkxefsc3uaX3LoZLzD9sOAFCWuFICAACsQCgBAABWIJQAAAArEEoAAIAVCCUAAMAKhBIAAGAFj4eSqVOnyuFwuA3NmjXz9GoAAICXKZP3lLRs2VIrV678v5X4VLrXoQAAgFIqk7Tg4+OjiIiIslg0AADwUmVyT8nOnTtVt25dNWrUSDfddJP27NlTbNu8vDxlZWW5DQAAoPLx+JWS9u3ba+7cuWratKn279+vhIQEde7cWd99950CAwMLtU9MTFRCQoKny0AlwGvvAcC7ePxKSZ8+fXTjjTeqVatWiomJ0eeff66MjAy9//77RbaPj49XZmama9i7d6+nSwIAAOeBMr8DNSQkRBdffLFSUlKKnO50OuV0Osu6DAAAYLkyf0/JkSNHtGvXLtWpU6esVwUAAM5jHg8lDzzwgNauXavdu3fr66+/1g033KCqVatq2LBhnl4VAADwIh7/+ObXX3/VsGHDdOjQIYWFhalTp05av369wsLCPL0qAADgRTweShYsWODpRQIAgEqAv30DAACsQCgBAABWIJQAAAArEEoAAIAV+PO98KiSvPq9JHg9PABUPlwpAQAAViCUAAAAKxBKAACAFQglAADACoQSAABgBUIJAACwAqEEAABYgVACAACsQCgBAABW4I2uRfDUW0lR8UqyL3l7LADYgSslAADACoQSAABgBUIJAACwAqEEAABYgVACAACsQCgBAABWIJQAAAArEEoAAIAVCCUAAMAKhBIAAGAFXjOPSu9Mr6LnNfQAUD64UgIAAKxAKAEAAFYglAAAACsQSgAAgBUIJQAAwAqEEgAAYAVCCQAAsAKhBAAAWIFQAgAArEAoAQAAVuA188AZnOk19FLJXkVfkuWUhCdee++pPlVW59v2K896PXGc27Ttzkfn2/F5Mq6UAAAAKxBKAACAFQglAADACoQSAABgBUIJAACwQpmFkpkzZ6pBgwby8/NT+/bt9c0335TVqgAAgBcok1Dy3nvvaeLEiZoyZYq2bNmi1q1bKyYmRgcOHCiL1QEAAC9QJqHk+eef1+23367Ro0erRYsWevXVV1W9enW9+eabZbE6AADgBTz+8rSjR49q8+bNio+Pd42rUqWKevXqpXXr1hVqn5eXp7y8PNfXmZmZkqSsrCxPlyZJys/LKZPlwrNKsv9t2pflWa8nzo2S1FJW56A3ON+2X3nW64nj3KZtdz6qqOOzYJnGmLNfiPGw3377zUgyX3/9tdv4SZMmmXbt2hVqP2XKFCOJgYGBgYGBwQuGvXv3nnWGqPDXzMfHx2vixImur/Pz8/XHH3+oZs2acjgcFVhZ2cvKylJkZKT27t2roKCgii6n3NBv+l0Z0G/6XRmc3O/AwEAdPnxYdevWPevleTyU1KpVS1WrVlV6errb+PT0dEVERBRq73Q65XQ63caFhIR4uiyrBQUFVaqDuAD9rlzod+VCvyuXgn4HBwef03I8fqOrr6+v2rRpo1WrVrnG5efna9WqVYqOjvb06gAAgJcok49vJk6cqJEjR6pt27Zq166dXnjhBWVnZ2v06NFlsToAAOAFyiSUDBkyRAcPHtRjjz2mtLQ0XXbZZVq6dKlq165dFqs7bzmdTk2ZMqXQx1fejn7T78qAftPvysDT/XYYcy7P7gAAAHgGf/sGAABYgVACAACsQCgBAABWIJQAAAArEEoAAIAVCCXlYNasWWrVqpXrjXfR0dFasmSJa3pubq7i4uJUs2ZNBQQEaNCgQYXeiHs+OlO/u3XrJofD4TbcddddFVix502bNk0Oh0Pjx493jfPW/X2yovrtrft76tSphfrVrFkz13Rv3d9n6re37m9J+u2333TzzTerZs2a8vf316WXXqpNmza5phtj9Nhjj6lOnTry9/dXr169tHPnzgqs2DPO1O9Ro0YV2ue9e/cu1Toq/G/fVAb16tXTtGnT1KRJExljNG/ePPXv319bt25Vy5YtNWHCBC1evFgffPCBgoODNXbsWA0cOFBfffVVRZd+Ts7Ub0m6/fbb9fjjj7vmqV69ekWV63EbN27Ua6+9platWrmN99b9XaC4fkveu79btmyplStXur728fm/b63evL9P12/JO/f3n3/+qY4dO6p79+5asmSJwsLCtHPnTl1wwQWuNs8884xeeuklzZs3Tw0bNtSjjz6qmJgYff/99/Lz86vA6s9eSfotSb1799acOXNcX5f6/SVn/af8cE4uuOAC88Ybb5iMjAxTrVo188EHH7im/fDDD0aSWbduXQVWWDYK+m2MMV27djX33XdfxRZURg4fPmyaNGliVqxY4dZPb9/fxfXbGO/d31OmTDGtW7cucpo37+/T9dsY793fDz30kOnUqVOx0/Pz801ERISZPn26a1xGRoZxOp3m3XffLY8Sy8SZ+m2MMSNHjjT9+/c/p/Xw8U05O3HihBYsWKDs7GxFR0dr8+bNOnbsmHr16uVq06xZM9WvX1/r1q2rwEo969R+F0hKSlKtWrV0ySWXKD4+Xjk5ORVYpefExcWpb9++bvtVktfv7+L6XcBb9/fOnTtVt25dNWrUSDfddJP27Nkjyfv3d3H9LuCN+/s///mP2rZtqxtvvFHh4eG6/PLL9frrr7ump6amKi0tzW2fBwcHq3379uf1Pj9TvwusWbNG4eHhatq0qe6++24dOnSoVOvh45ty8u233yo6Olq5ubkKCAjQwoUL1aJFC23btk2+vr6F/jJy7dq1lZaWVjHFelBx/Zak4cOHKyoqSnXr1tX27dv10EMPKTk5WR9//HEFV31uFixYoC1btmjjxo2FpqWlpXnt/j5dvyXv3d/t27fX3Llz1bRpU+3fv18JCQnq3LmzvvvuO6/e36frd2BgoNfu759//lmzZs3SxIkT9fDDD2vjxo2699575evrq5EjR7r266l/VuV83+dn6rf090c3AwcOVMOGDbVr1y49/PDD6tOnj9atW6eqVauWbEXndJ0FJZaXl2d27txpNm3aZCZPnmxq1aplduzYYZKSkoyvr2+h9ldeeaV58MEHK6BSzyqu30VZtWqVkWRSUlLKuUrP2bNnjwkPDzf/7//9P9e4ky9je+v+PlO/i+IN+7sof/75pwkKCjJvvPGG1+7vopzc76J4y/6uVq2aiY6Odhs3btw406FDB2OMMV999ZWRZPbt2+fW5sYbbzSDBw8utzo97Uz9LsquXbuMJLNy5coSr4ePb8qJr6+vLrroIrVp00aJiYlq3bq1XnzxRUVEROjo0aPKyMhwa5+enq6IiIiKKdaDiut3Udq3by9JSklJKc8SPWrz5s06cOCArrjiCvn4+MjHx0dr167VSy+9JB8fH9WuXdsr9/eZ+n3ixIlC83jD/i5KSEiILr74YqWkpHj9+X2yk/tdFG/Z33Xq1HFd7S3QvHlz10dXBfv11Ceszvd9fqZ+F6VRo0aqVatWqfY5oaSC5OfnKy8vT23atFG1atW0atUq17Tk5GTt2bPH7d4Lb1HQ76Js27ZN0t8H//mqZ8+e+vbbb7Vt2zbX0LZtW910002u/3vj/j5Tv4u6dOsN+7soR44c0a5du1SnTp1KdX6f3O+ieMv+7tixo5KTk93G/fTTT4qKipIkNWzYUBEREW77PCsrSxs2bDiv9/mZ+l2UX3/9VYcOHSrdPj/razkoscmTJ5u1a9ea1NRUs337djN58mTjcDjM8uXLjTHG3HXXXaZ+/frmiy++MJs2bTLR0dGFLpOdj07X75SUFPP444+bTZs2mdTUVLNo0SLTqFEj06VLl4ou2+NO/RjDW/f3qU7utzfv7/vvv9+sWbPGpKammq+++sr06tXL1KpVyxw4cMAY4737+3T99ub9/c033xgfHx/z1FNPmZ07d5qkpCRTvXp1884777jaTJs2zYSEhJhFixaZ7du3m/79+5uGDRuav/76qwIrPzdn6vfhw4fNAw88YNatW2dSU1PNypUrzRVXXGGaNGlicnNzS7weQkk5uPXWW01UVJTx9fU1YWFhpmfPnq5AYowxf/31l7nnnnvMBRdcYKpXr25uuOEGs3///gqs2DNO1+89e/aYLl26mNDQUON0Os1FF11kJk2aZDIzMyu4as87NZR46/4+1cn99ub9PWTIEFOnTh3j6+trLrzwQjNkyBC3+ya8dX+frt/evL+NMebTTz81l1xyiXE6naZZs2Zm9uzZbtPz8/PNo48+amrXrm2cTqfp2bOnSU5OrqBqPed0/c7JyTHXXHONCQsLM9WqVTNRUVHm9ttvN2lpaaVah8MYY872cg4AAICncE8JAACwAqEEAABYgVACAACsQCgBAABWIJQAAAArEEoAAIAVCCUAAMAKhBIAAGAFQgkAALACoQQAAFiBUAIAAKzw/wFzkyRwO09J7AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = X_test.copy()\n",
        "df_test['score'] = y_test_scores\n",
        "df_test['cluster'] = np.where(df_test['score']>35, 0, 1)\n",
        "aa = df_test['cluster'].value_counts()\n",
        "print(y_test_scores)\n",
        "print(aa)\n",
        "df_test\n",
        "#df_test.groupby('cluster').mean()"
      ],
      "metadata": {
        "id": "ZIfeEIH0-8J-",
        "outputId": "9a8b326c-712d-49c9-b4c3-ee64106b6590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      29.686528\n",
            "1      30.603348\n",
            "2      31.926292\n",
            "3      36.828429\n",
            "4      37.668265\n",
            "         ...    \n",
            "193    31.334064\n",
            "194    31.432681\n",
            "195    31.114762\n",
            "196    32.408419\n",
            "197    31.022242\n",
            "Length: 198, dtype: float64\n",
            "1    176\n",
            "0     22\n",
            "Name: cluster, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0         1         2         3         4         5         6  \\\n",
              "80  2.097582  3.919309  3.701641  3.632746  4.934787  2.653211  4.132455   \n",
              "13  2.013703  3.060130  1.640646  8.463126  3.694937  1.448490  1.693329   \n",
              "81  4.686469  1.685222  2.491703  2.665692  3.739461  1.817014  1.063535   \n",
              "88  4.995176  3.282428  5.279045  6.208318  4.220128  1.571349  2.669127   \n",
              "55  5.221848  4.033182  3.565481  1.626504  4.602411  2.142364  3.473699   \n",
              "..       ...       ...       ...       ...       ...       ...       ...   \n",
              "14  3.817609  2.399615  2.192956  8.130535  3.750435  1.747160  2.551118   \n",
              "6   1.510349  4.673163  3.369808  5.944179  4.529162  2.129095  4.785614   \n",
              "88  5.792597  4.036893  5.210788  2.672993  5.981865  4.374747  4.467314   \n",
              "44  5.086731  3.022572  3.246790  1.657870  3.707817  2.177779  3.240610   \n",
              "87  4.205899  2.231062  3.331016  3.704475  4.287406  1.847830  1.272282   \n",
              "\n",
              "           7         8         9  ...       992       993       994       995  \\\n",
              "80  1.983103  4.259198  1.758823  ...  0.423848  0.523479  0.505645  0.779256   \n",
              "13  2.085983  0.541708  4.566147  ...  1.679876  0.520369  1.524850  1.137069   \n",
              "81  1.819567  1.894465  1.421712  ...  0.424682  0.661888  0.863042  0.456789   \n",
              "88  1.365000  3.387731  2.906401  ...  0.144746  0.249454  0.337185  0.303595   \n",
              "55  2.833517  2.727975  1.565750  ...  0.968076  0.486483  0.378989  0.364017   \n",
              "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
              "14  1.838926  1.856339  3.898397  ...  0.726381  1.239488  1.681631  1.366392   \n",
              "6   2.946359  1.913700  3.195328  ...  0.751946  0.624558  0.635487  0.170271   \n",
              "88  2.573553  1.850048  2.299505  ...  0.609314  0.179722  0.206491  0.465355   \n",
              "44  2.582890  2.203594  1.718615  ...  1.335876  0.597730  0.135358  0.682216   \n",
              "87  2.248918  2.441842  1.809314  ...  0.415653  0.316156  0.368470  0.562391   \n",
              "\n",
              "         996       997       998       999      score  cluster  \n",
              "80  0.225051  0.572244  0.446165  0.674062  32.878319        1  \n",
              "13  1.059685  1.159663  0.946073  1.287431  32.633174        1  \n",
              "81  0.527456  0.110967  0.395773  0.209944  29.966416        1  \n",
              "88  0.182857  0.354574  0.421540  0.846186  33.364852        1  \n",
              "55  0.724403  0.588913  0.793974  0.420980  32.530439        1  \n",
              "..       ...       ...       ...       ...        ...      ...  \n",
              "14  1.615460  0.547803  1.028659  1.222233  33.880704        1  \n",
              "6   0.698532  0.799244  0.862949  0.960635  30.392921        1  \n",
              "88  0.680827  0.605589  0.878099  0.539569  33.364852        1  \n",
              "44  0.595199  0.555942  0.166230  0.542932  32.478342        1  \n",
              "87  0.322747  0.407140  0.445607  0.311265  34.715867        1  \n",
              "\n",
              "[198 rows x 1002 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90df94b3-694c-4dcf-b235-7a4f53f469b4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>992</th>\n",
              "      <th>993</th>\n",
              "      <th>994</th>\n",
              "      <th>995</th>\n",
              "      <th>996</th>\n",
              "      <th>997</th>\n",
              "      <th>998</th>\n",
              "      <th>999</th>\n",
              "      <th>score</th>\n",
              "      <th>cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>2.097582</td>\n",
              "      <td>3.919309</td>\n",
              "      <td>3.701641</td>\n",
              "      <td>3.632746</td>\n",
              "      <td>4.934787</td>\n",
              "      <td>2.653211</td>\n",
              "      <td>4.132455</td>\n",
              "      <td>1.983103</td>\n",
              "      <td>4.259198</td>\n",
              "      <td>1.758823</td>\n",
              "      <td>...</td>\n",
              "      <td>0.423848</td>\n",
              "      <td>0.523479</td>\n",
              "      <td>0.505645</td>\n",
              "      <td>0.779256</td>\n",
              "      <td>0.225051</td>\n",
              "      <td>0.572244</td>\n",
              "      <td>0.446165</td>\n",
              "      <td>0.674062</td>\n",
              "      <td>32.878319</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2.013703</td>\n",
              "      <td>3.060130</td>\n",
              "      <td>1.640646</td>\n",
              "      <td>8.463126</td>\n",
              "      <td>3.694937</td>\n",
              "      <td>1.448490</td>\n",
              "      <td>1.693329</td>\n",
              "      <td>2.085983</td>\n",
              "      <td>0.541708</td>\n",
              "      <td>4.566147</td>\n",
              "      <td>...</td>\n",
              "      <td>1.679876</td>\n",
              "      <td>0.520369</td>\n",
              "      <td>1.524850</td>\n",
              "      <td>1.137069</td>\n",
              "      <td>1.059685</td>\n",
              "      <td>1.159663</td>\n",
              "      <td>0.946073</td>\n",
              "      <td>1.287431</td>\n",
              "      <td>32.633174</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>4.686469</td>\n",
              "      <td>1.685222</td>\n",
              "      <td>2.491703</td>\n",
              "      <td>2.665692</td>\n",
              "      <td>3.739461</td>\n",
              "      <td>1.817014</td>\n",
              "      <td>1.063535</td>\n",
              "      <td>1.819567</td>\n",
              "      <td>1.894465</td>\n",
              "      <td>1.421712</td>\n",
              "      <td>...</td>\n",
              "      <td>0.424682</td>\n",
              "      <td>0.661888</td>\n",
              "      <td>0.863042</td>\n",
              "      <td>0.456789</td>\n",
              "      <td>0.527456</td>\n",
              "      <td>0.110967</td>\n",
              "      <td>0.395773</td>\n",
              "      <td>0.209944</td>\n",
              "      <td>29.966416</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>4.995176</td>\n",
              "      <td>3.282428</td>\n",
              "      <td>5.279045</td>\n",
              "      <td>6.208318</td>\n",
              "      <td>4.220128</td>\n",
              "      <td>1.571349</td>\n",
              "      <td>2.669127</td>\n",
              "      <td>1.365000</td>\n",
              "      <td>3.387731</td>\n",
              "      <td>2.906401</td>\n",
              "      <td>...</td>\n",
              "      <td>0.144746</td>\n",
              "      <td>0.249454</td>\n",
              "      <td>0.337185</td>\n",
              "      <td>0.303595</td>\n",
              "      <td>0.182857</td>\n",
              "      <td>0.354574</td>\n",
              "      <td>0.421540</td>\n",
              "      <td>0.846186</td>\n",
              "      <td>33.364852</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>5.221848</td>\n",
              "      <td>4.033182</td>\n",
              "      <td>3.565481</td>\n",
              "      <td>1.626504</td>\n",
              "      <td>4.602411</td>\n",
              "      <td>2.142364</td>\n",
              "      <td>3.473699</td>\n",
              "      <td>2.833517</td>\n",
              "      <td>2.727975</td>\n",
              "      <td>1.565750</td>\n",
              "      <td>...</td>\n",
              "      <td>0.968076</td>\n",
              "      <td>0.486483</td>\n",
              "      <td>0.378989</td>\n",
              "      <td>0.364017</td>\n",
              "      <td>0.724403</td>\n",
              "      <td>0.588913</td>\n",
              "      <td>0.793974</td>\n",
              "      <td>0.420980</td>\n",
              "      <td>32.530439</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>3.817609</td>\n",
              "      <td>2.399615</td>\n",
              "      <td>2.192956</td>\n",
              "      <td>8.130535</td>\n",
              "      <td>3.750435</td>\n",
              "      <td>1.747160</td>\n",
              "      <td>2.551118</td>\n",
              "      <td>1.838926</td>\n",
              "      <td>1.856339</td>\n",
              "      <td>3.898397</td>\n",
              "      <td>...</td>\n",
              "      <td>0.726381</td>\n",
              "      <td>1.239488</td>\n",
              "      <td>1.681631</td>\n",
              "      <td>1.366392</td>\n",
              "      <td>1.615460</td>\n",
              "      <td>0.547803</td>\n",
              "      <td>1.028659</td>\n",
              "      <td>1.222233</td>\n",
              "      <td>33.880704</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.510349</td>\n",
              "      <td>4.673163</td>\n",
              "      <td>3.369808</td>\n",
              "      <td>5.944179</td>\n",
              "      <td>4.529162</td>\n",
              "      <td>2.129095</td>\n",
              "      <td>4.785614</td>\n",
              "      <td>2.946359</td>\n",
              "      <td>1.913700</td>\n",
              "      <td>3.195328</td>\n",
              "      <td>...</td>\n",
              "      <td>0.751946</td>\n",
              "      <td>0.624558</td>\n",
              "      <td>0.635487</td>\n",
              "      <td>0.170271</td>\n",
              "      <td>0.698532</td>\n",
              "      <td>0.799244</td>\n",
              "      <td>0.862949</td>\n",
              "      <td>0.960635</td>\n",
              "      <td>30.392921</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>5.792597</td>\n",
              "      <td>4.036893</td>\n",
              "      <td>5.210788</td>\n",
              "      <td>2.672993</td>\n",
              "      <td>5.981865</td>\n",
              "      <td>4.374747</td>\n",
              "      <td>4.467314</td>\n",
              "      <td>2.573553</td>\n",
              "      <td>1.850048</td>\n",
              "      <td>2.299505</td>\n",
              "      <td>...</td>\n",
              "      <td>0.609314</td>\n",
              "      <td>0.179722</td>\n",
              "      <td>0.206491</td>\n",
              "      <td>0.465355</td>\n",
              "      <td>0.680827</td>\n",
              "      <td>0.605589</td>\n",
              "      <td>0.878099</td>\n",
              "      <td>0.539569</td>\n",
              "      <td>33.364852</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>5.086731</td>\n",
              "      <td>3.022572</td>\n",
              "      <td>3.246790</td>\n",
              "      <td>1.657870</td>\n",
              "      <td>3.707817</td>\n",
              "      <td>2.177779</td>\n",
              "      <td>3.240610</td>\n",
              "      <td>2.582890</td>\n",
              "      <td>2.203594</td>\n",
              "      <td>1.718615</td>\n",
              "      <td>...</td>\n",
              "      <td>1.335876</td>\n",
              "      <td>0.597730</td>\n",
              "      <td>0.135358</td>\n",
              "      <td>0.682216</td>\n",
              "      <td>0.595199</td>\n",
              "      <td>0.555942</td>\n",
              "      <td>0.166230</td>\n",
              "      <td>0.542932</td>\n",
              "      <td>32.478342</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>4.205899</td>\n",
              "      <td>2.231062</td>\n",
              "      <td>3.331016</td>\n",
              "      <td>3.704475</td>\n",
              "      <td>4.287406</td>\n",
              "      <td>1.847830</td>\n",
              "      <td>1.272282</td>\n",
              "      <td>2.248918</td>\n",
              "      <td>2.441842</td>\n",
              "      <td>1.809314</td>\n",
              "      <td>...</td>\n",
              "      <td>0.415653</td>\n",
              "      <td>0.316156</td>\n",
              "      <td>0.368470</td>\n",
              "      <td>0.562391</td>\n",
              "      <td>0.322747</td>\n",
              "      <td>0.407140</td>\n",
              "      <td>0.445607</td>\n",
              "      <td>0.311265</td>\n",
              "      <td>34.715867</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>198 rows × 1002 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90df94b3-694c-4dcf-b235-7a4f53f469b4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-90df94b3-694c-4dcf-b235-7a4f53f469b4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-90df94b3-694c-4dcf-b235-7a4f53f469b4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-030abfc2-94cc-4170-9402-230b1a014e65\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-030abfc2-94cc-4170-9402-230b1a014e65')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-030abfc2-94cc-4170-9402-230b1a014e65 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = pd.read_csv(\"data/tsne_data/TrainoCaso1/time_series_tsne.csv\")\n",
        "\n",
        "x"
      ],
      "metadata": {
        "id": "wLhV1r1scjTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pyod.models.auto_encoder import AutoEncoder\n",
        "from pyod.utils.data import generate_data\n",
        "contamination = 0.1  # percentage of outliers\n",
        "n_train = 500  # number of training points\n",
        "n_test = 500  # number of testing points\n",
        "n_features = 25 # Number of features\n",
        "X_train, y_train, X_test, y_test = generate_data(\n",
        "   n_train=n_train, n_test=n_test,\n",
        "   n_features= n_features,\n",
        "   contamination=contamination,random_state=1234)\n",
        "X_train = pd.DataFrame(X_train)\n",
        "X_test = pd.DataFrame(X_test)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(np.arange(1,25),X_train)"
      ],
      "metadata": {
        "id": "I2f0Wy-_s_rP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Dataset 3-dimensionale</h1>"
      ],
      "metadata": {
        "id": "O_xlKhSScp_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "path_to_normal_data = 'data/processed_data/TrainoCaso1/time_series.csv'\n",
        "path_to_anomaly_data = 'data/processed_data/TrainoCaso2/time_series.csv'\n",
        "\n",
        "# Reading the CSV files into DataFrames\n",
        "normal_data_df = pd.read_csv(path_to_normal_data)\n",
        "anomaly_data_df = pd.read_csv(path_to_anomaly_data)\n",
        "\n",
        "#Sorting by acquisition number\n",
        "normal_data_df = normal_data_df.sort_values(by=['Acquisition Number', 'Time'])\n",
        "anomaly_data_df = anomaly_data_df.sort_values(by=['Acquisition Number', 'Time'])\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(\"Normal Data:\")\n",
        "print(normal_data_df.head())\n",
        "\n",
        "print(\"\\nAnomaly Data:\")\n",
        "print(anomaly_data_df.head())\n",
        "\n",
        "print(\"Shape of Normal Data:\", normal_data_df.shape)\n",
        "print(\"Shape of Anomaly Data:\", anomaly_data_df.shape)"
      ],
      "metadata": {
        "id": "oHe-ge3Kcw0L",
        "outputId": "66d827ac-cc0f-4421-da37-a6e8463f308e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal Data:\n",
            "       Acquisition Number  Time  Axe1X  Axe1Y  Axe1Z  Axe2X  Axe2Y  Axe2Z\n",
            "80185                   1     1   -196  -3877   -964   3641    421  -1542\n",
            "80186                   1     2    925  -4433   -392   3866    412   -952\n",
            "80187                   1     3    346  -4324   -165   3733    519  -1290\n",
            "80188                   1     4   -200  -3315  -2497   3507    524  -1468\n",
            "80189                   1     5    617  -4483   -919   4062    360  -1720\n",
            "\n",
            "Anomaly Data:\n",
            "       Acquisition Number  Time  Axe1X  Axe1Y  Axe1Z  Axe2X  Axe2Y  Axe2Z\n",
            "79808                   1     1   -164  -3971    -50   3636    529  -1412\n",
            "79809                   1     2    173  -4775   1023   3933    530   -840\n",
            "79810                   1     3   -388  -4068    282   3841    422  -1331\n",
            "79811                   1     4    -19  -2834  -3462   3595    555  -1337\n",
            "79812                   1     5    670  -3814  -2641   3932    494  -1728\n",
            "Shape of Normal Data: (114774, 8)\n",
            "Shape of Anomaly Data: (108234, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset index before concatenation\n",
        "normal_data_df.reset_index(drop=True, inplace=True)\n",
        "anomaly_data_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Concatenate the accelerometer readings into a single vector for each time step\n",
        "#normal_data_concatenated = pd.concat([pd.concat([normal_data_df['Axe1X'],normal_data_df['Axe2X'].rename(columns={'Axe2X':'Axe1X'})]), normal_data_df['Axe1Y'], normal_data_df['Axe1Z'],\n",
        " #                                     normal_data_df['Axe2X'], normal_data_df['Axe2Y'], normal_data_df['Axe2Z']], axis=1)\n",
        "\n",
        "#anomaly_data_concatenated = pd.concat([anomaly_data_df['Axe1X'], anomaly_data_df['Axe1Y'], anomaly_data_df['Axe1Z'],\n",
        "#                                       anomaly_data_df['Axe2X'], anomaly_data_df['Axe2Y'], anomaly_data_df['Axe2Z']], axis=1)\n",
        "\n",
        "df1 = normal_data_df[['Acquisition Number', 'Time','Axe1X','Axe1Y','Axe1Z']]\n",
        "df2 = normal_data_df[['Acquisition Number', 'Time','Axe2X','Axe2Y','Axe2Z']]\n",
        "df2['Acquisition Number'] = df2['Acquisition Number'] + 106\n",
        "\n",
        "normal_data_concatenated = df1.merge(df2.rename(columns={\"Axe2X\": \"Axe1X\", \"Axe2Y\": \"Axe1Y\", \"Axe2Z\": \"Axe1Z\"}),how='outer')\n",
        "\n",
        "df1 = anomaly_data_df[['Acquisition Number', 'Time','Axe1X','Axe1Y','Axe1Z']]\n",
        "df2 = anomaly_data_df[['Acquisition Number', 'Time','Axe2X','Axe2Y','Axe2Z']]\n",
        "df2['Acquisition Number'] = df2['Acquisition Number'] + 99\n",
        "\n",
        "anomaly_data_concatenated = df1.merge(df2.rename(columns={\"Axe2X\": \"Axe1X\", \"Axe2Y\": \"Axe1Y\", \"Axe2Z\": \"Axe1Z\"}),how='outer')\n",
        "\n",
        "# Check the shape again\n",
        "print(\"Shape of Normal Data after Concatenation:\", normal_data_concatenated.shape)\n",
        "print(\"Shape of Anomaly Data after Concatenation:\", anomaly_data_concatenated.shape)"
      ],
      "metadata": {
        "id": "PeNKnqBZczIY",
        "outputId": "02dfd2ef-cea2-4e3c-a911-c75d368f1106",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Normal Data after Concatenation: (229548, 5)\n",
            "Shape of Anomaly Data after Concatenation: (216468, 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-a7bad65caa8e>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df2['Acquisition Number'] = df2['Acquisition Number'] + 106\n",
            "<ipython-input-54-a7bad65caa8e>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df2['Acquisition Number'] = df2['Acquisition Number'] + 99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Calcolo del massimo numero di time steps per ogni Acquisition Number\n",
        "max_steps_normal = normal_data_concatenated.groupby('Acquisition Number')['Time'].max()\n",
        "max_steps_anomaly = anomaly_data_concatenated.groupby('Acquisition Number')['Time'].max()\n",
        "\n",
        "# Trova il minimo dei massimi\n",
        "min_of_max_steps = max_steps_anomaly.min()\n",
        "print(min_of_max_steps)\n",
        "\n",
        "def process_acquisition(group):\n",
        "    # Drop the 'Acquisition Number' and 'Time' columns\n",
        "    features = group.drop(['Acquisition Number', 'Time'], axis=1)\n",
        "\n",
        "    # Calcolare la media delle caratteristiche (se necessario)\n",
        "    if len(features) < min_of_max_steps:\n",
        "        mean_values = features.mean()\n",
        "        # Creare un DataFrame con le righe da aggiungere\n",
        "        rows_to_add = pd.DataFrame([mean_values] * (min_of_max_steps - len(features)))\n",
        "        # Utilizzare concat invece di append\n",
        "        features = pd.concat([features, rows_to_add], ignore_index=True)\n",
        "\n",
        "    # Normalize the features\n",
        "    normalized_features = scaler.fit_transform(features)\n",
        "\n",
        "    # Pad sequences to the minimum of the maximum lengths\n",
        "    padded_features = pad_sequences([normalized_features], maxlen=min_of_max_steps, dtype='float32', padding='post')\n",
        "    return padded_features[0]\n",
        "\n",
        "# Applicare la funzione modificata a normal_data e anomaly_data\n",
        "normal_data_processed = normal_data_concatenated.groupby('Acquisition Number').apply(process_acquisition)\n",
        "anomaly_data_processed = anomaly_data_concatenated.groupby('Acquisition Number').apply(process_acquisition)\n",
        "\n",
        "# Convertire i dati processati in array per LSTM\n",
        "normal_data_lstm = np.array(normal_data_processed.tolist())\n",
        "anomaly_data_lstm = np.array(anomaly_data_processed.tolist())\n",
        "\n",
        "# Check the shapes of the processed data\n",
        "normal_data_lstm.shape, anomaly_data_lstm.shape\n"
      ],
      "metadata": {
        "id": "6jusCUEEc29S",
        "outputId": "c4ea4b9f-ccc6-45d6-a617-497c10b1c976",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1093\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((212, 1093, 3), (198, 1093, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normal_data_lstm"
      ],
      "metadata": {
        "id": "XuWb395bfS13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_series(series_3d, target_length):\n",
        "    \"\"\"\n",
        "    Suddivide ogni serie temporale in un array tridimensionale in più serie temporali di lunghezza target.\n",
        "\n",
        "    :param series_3d: Array tridimensionale di serie temporali.\n",
        "    :param target_length: Lunghezza target delle nuove serie temporali.\n",
        "    :return: Array tridimensionale con serie temporali suddivise.\n",
        "    \"\"\"\n",
        "    split_series = []\n",
        "    for series in series_3d:\n",
        "        for start_idx in range(0, len(series), target_length):\n",
        "            end_idx = start_idx + target_length\n",
        "            # Seleziona la sotto-serie temporale\n",
        "            sub_series = series[start_idx:end_idx]\n",
        "            # Se la sotto-serie temporale è più corta della lunghezza target, escludila\n",
        "            if len(sub_series) == target_length:\n",
        "                split_series.append(sub_series)\n",
        "\n",
        "    return np.array(split_series)\n",
        "\n",
        "# Applicare la funzione di suddivisione a normal_data_lstm e anomaly_data_lstm\n",
        "normal_data_split = split_series(normal_data_lstm, 1000)\n",
        "anomaly_data_split = split_series(anomaly_data_lstm, 1000)\n",
        "\n",
        "normal_data_split.shape, anomaly_data_split.shape"
      ],
      "metadata": {
        "id": "r7OAWBU8dOuX",
        "outputId": "a1235af2-f83c-42d0-f914-cba2602db765",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((212, 1000, 3), (198, 1000, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the normal data into training and validation sets\n",
        "normal_train, normal_val = train_test_split(normal_data_split, test_size=0.2, shuffle=True, random_state=0)\n",
        "\n",
        "# Checking the shape of the splits\n",
        "normal_train.shape, normal_val.shape"
      ],
      "metadata": {
        "id": "opjMPz9hdX3j",
        "outputId": "679f3368-6f71-4f3f-a8b2-4fb1fdd41fb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3561, 50, 3), (891, 50, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normal_train_2d = normal_train.reshape([50*3561, 3])\n",
        "normal_val_2d = normal_val.reshape([50*891, 3])\n",
        "\n",
        "anomaly_data_split_2d = anomaly_data_split.reshape([50*4158, 3])\n",
        "\n",
        "normal_train_2d.shape, normal_val_2d.shape, anomaly_data_split_2d.shape"
      ],
      "metadata": {
        "id": "MknbM7foeaUI",
        "outputId": "e3b52898-0efd-4ba4-d985-b3618867601c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((178050, 3), (44550, 3), (207900, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "anomaly_data_split_2d"
      ],
      "metadata": {
        "id": "w_-AJuBuqYbX",
        "outputId": "a009743b-6ab2-4df1-81c7-6fb2da17dc3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-6.1006058e-02, -4.0027456e+00,  4.8493114e+00],\n",
              "       [-7.6020664e-01, -5.3294307e-01,  3.1479998e+00],\n",
              "       [-3.0030465e-01,  5.5232611e+00, -5.4481015e+00],\n",
              "       ...,\n",
              "       [ 2.6754525e-01, -3.4152241e-03, -2.7216685e-01],\n",
              "       [ 7.6404756e-01,  4.5385778e-01,  2.3902944e-01],\n",
              "       [ 1.1477529e-01,  4.3155178e-01,  2.3902944e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyod.models.vae import VAE\n",
        "clf = VAE(encoder_neurons=[243, 81, 3], decoder_neurons=[3, 81, 243], epochs=20, batch_size=64, dropout_rate=0.2)\n",
        "\n",
        "history = clf.fit(\n",
        "    normal_train_2d\n",
        "    )"
      ],
      "metadata": {
        "id": "bAMIIpNXdb1t",
        "outputId": "6eb242c0-a64f-4eb4-9e91-6093eb0d7bcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 3)]                  0         []                            \n",
            "                                                                                                  \n",
            " dense_11 (Dense)            (None, 3)                    12        ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " dense_12 (Dense)            (None, 243)                  972       ['dense_11[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 243)                  0         ['dense_12[0][0]']            \n",
            "                                                                                                  \n",
            " dense_13 (Dense)            (None, 81)                   19764     ['dropout_6[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)         (None, 81)                   0         ['dense_13[0][0]']            \n",
            "                                                                                                  \n",
            " dense_14 (Dense)            (None, 3)                    246       ['dropout_7[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)         (None, 3)                    0         ['dense_14[0][0]']            \n",
            "                                                                                                  \n",
            " dense_15 (Dense)            (None, 2)                    8         ['dropout_8[0][0]']           \n",
            "                                                                                                  \n",
            " dense_16 (Dense)            (None, 2)                    8         ['dropout_8[0][0]']           \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)           (None, 2)                    0         ['dense_15[0][0]',            \n",
            "                                                                     'dense_16[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21010 (82.07 KB)\n",
            "Trainable params: 21010 (82.07 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 2)]               0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 2)                 6         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 3)                 9         \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 3)                 0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 81)                324       \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 81)                0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 243)               19926     \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 243)               0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 3)                 732       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20997 (82.02 KB)\n",
            "Trainable params: 20997 (82.02 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 3)]                  0         []                            \n",
            "                                                                                                  \n",
            " model_3 (Functional)        [(None, 2),                  21010     ['input_3[0][0]']             \n",
            "                              (None, 2),                                                          \n",
            "                              (None, 2)]                                                          \n",
            "                                                                                                  \n",
            " model_4 (Functional)        (None, 3)                    20997     ['model_3[0][2]']             \n",
            "                                                                                                  \n",
            " dense_11 (Dense)            (None, 3)                    12        ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " dense_12 (Dense)            (None, 243)                  972       ['dense_11[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 243)                  0         ['dense_12[0][0]']            \n",
            "                                                                                                  \n",
            " dense_13 (Dense)            (None, 81)                   19764     ['dropout_6[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)         (None, 81)                   0         ['dense_13[0][0]']            \n",
            "                                                                                                  \n",
            " dense_14 (Dense)            (None, 3)                    246       ['dropout_7[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)         (None, 3)                    0         ['dense_14[0][0]']            \n",
            "                                                                                                  \n",
            " dense_16 (Dense)            (None, 2)                    8         ['dropout_8[0][0]']           \n",
            "                                                                                                  \n",
            " dense_15 (Dense)            (None, 2)                    8         ['dropout_8[0][0]']           \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TF  (None, 2)                    0         ['dense_16[0][0]']            \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.math.square_1 (TFOpLamb  (None, 2)                    0         ['dense_15[0][0]']            \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.subtract_3 (TFOpLa  (None, 2)                    0         ['tf.__operators__.add_2[0][0]\n",
            " mbda)                                                              ',                            \n",
            "                                                                     'tf.math.square_1[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.exp_1 (TFOpLambda)  (None, 2)                    0         ['dense_16[0][0]']            \n",
            "                                                                                                  \n",
            " tf.math.subtract_4 (TFOpLa  (None, 2)                    0         ['tf.math.subtract_3[0][0]',  \n",
            " mbda)                                                               'tf.math.exp_1[0][0]']       \n",
            "                                                                                                  \n",
            " tf.math.reduce_sum_1 (TFOp  (None,)                      0         ['tf.math.subtract_4[0][0]']  \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_1 (TF  (None, 3)                    0         ['model_4[0][0]']             \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.cast_1 (TFOpLambda)      (None, 3)                    0         ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " tf.math.multiply_4 (TFOpLa  (None,)                      0         ['tf.math.reduce_sum_1[0][0]']\n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.math.squared_difference  (None, 3)                    0         ['tf.convert_to_tensor_1[0][0]\n",
            " _1 (TFOpLambda)                                                    ',                            \n",
            "                                                                     'tf.cast_1[0][0]']           \n",
            "                                                                                                  \n",
            " tf.math.subtract_5 (TFOpLa  (None,)                      0         ['tf.math.multiply_4[0][0]']  \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean_2 (TFO  (None,)                      0         ['tf.math.squared_difference_1\n",
            " pLambda)                                                           [0][0]']                      \n",
            "                                                                                                  \n",
            " tf.math.abs_1 (TFOpLambda)  (None,)                      0         ['tf.math.subtract_5[0][0]']  \n",
            "                                                                                                  \n",
            " tf.math.multiply_3 (TFOpLa  (None,)                      0         ['tf.math.reduce_mean_2[0][0]'\n",
            " mbda)                                                              ]                             \n",
            "                                                                                                  \n",
            " tf.math.multiply_5 (TFOpLa  (None,)                      0         ['tf.math.abs_1[0][0]']       \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TF  (None,)                      0         ['tf.math.multiply_3[0][0]',  \n",
            " OpLambda)                                                           'tf.math.multiply_5[0][0]']  \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean_3 (TFO  ()                           0         ['tf.__operators__.add_3[0][0]\n",
            " pLambda)                                                           ']                            \n",
            "                                                                                                  \n",
            " add_loss_1 (AddLoss)        ()                           0         ['tf.math.reduce_mean_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 42007 (164.09 KB)\n",
            "Trainable params: 42007 (164.09 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "2504/2504 [==============================] - 15s 5ms/step - loss: 3.0143 - val_loss: 2.9678\n",
            "Epoch 2/20\n",
            "2504/2504 [==============================] - 13s 5ms/step - loss: 3.0040 - val_loss: 2.9678\n",
            "Epoch 3/20\n",
            "2504/2504 [==============================] - 12s 5ms/step - loss: 3.0041 - val_loss: 2.9678\n",
            "Epoch 4/20\n",
            "2504/2504 [==============================] - 11s 4ms/step - loss: 3.0040 - val_loss: 2.9678\n",
            "Epoch 5/20\n",
            "2504/2504 [==============================] - 12s 5ms/step - loss: 3.0040 - val_loss: 2.9678\n",
            "Epoch 6/20\n",
            "2504/2504 [==============================] - 14s 6ms/step - loss: 3.0041 - val_loss: 2.9678\n",
            "Epoch 7/20\n",
            "2504/2504 [==============================] - 13s 5ms/step - loss: 3.0040 - val_loss: 2.9678\n",
            "Epoch 8/20\n",
            "2504/2504 [==============================] - 12s 5ms/step - loss: 3.0040 - val_loss: 2.9678\n",
            "Epoch 9/20\n",
            "2504/2504 [==============================] - 12s 5ms/step - loss: 3.0040 - val_loss: 2.9678\n",
            "Epoch 10/20\n",
            "2504/2504 [==============================] - 15s 6ms/step - loss: 3.0040 - val_loss: 2.9678\n",
            "Epoch 11/20\n",
            "2504/2504 [==============================] - 16s 6ms/step - loss: 3.0040 - val_loss: 2.9678\n",
            "Epoch 12/20\n",
            "2504/2504 [==============================] - 15s 6ms/step - loss: 3.0040 - val_loss: 2.9678\n",
            "Epoch 13/20\n",
            "2504/2504 [==============================] - 12s 5ms/step - loss: 3.0040 - val_loss: 2.9678\n",
            "Epoch 14/20\n",
            "2504/2504 [==============================] - 11s 4ms/step - loss: 3.0041 - val_loss: 2.9678\n",
            "Epoch 15/20\n",
            "2504/2504 [==============================] - 12s 5ms/step - loss: 3.0041 - val_loss: 2.9678\n",
            "Epoch 16/20\n",
            "2504/2504 [==============================] - 17s 7ms/step - loss: 3.0040 - val_loss: 2.9678\n",
            "Epoch 17/20\n",
            "2504/2504 [==============================] - 12s 5ms/step - loss: 3.0040 - val_loss: 2.9678\n",
            "Epoch 18/20\n",
            "2504/2504 [==============================] - 12s 5ms/step - loss: 3.0040 - val_loss: 2.9678\n",
            "Epoch 19/20\n",
            "2504/2504 [==============================] - 12s 5ms/step - loss: 3.0040 - val_loss: 2.9678\n",
            "Epoch 20/20\n",
            "2504/2504 [==============================] - 11s 5ms/step - loss: 3.0040 - val_loss: 2.9678\n",
            "5565/5565 [==============================] - 11s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = clf.predict(normal_val_2d)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(np.arange(1,a.size+1),a)\n"
      ],
      "metadata": {
        "id": "X60HOCfndqIk",
        "outputId": "f20492e6-dadb-496d-e0d4-2cb8f4024a8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1393/1393 [==============================] - 2s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7b1254620c40>]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"---------CASO 1----------\")\n",
        "print(f\"Numero di time series anomale: {np.count_nonzero(a == 1)} su {len(a)}\")\n",
        "print(f\"Numero di time series non anomale: {np.count_nonzero(a == 0)} su {len(a)}\")\n",
        "\n",
        "b = clf.predict(anomaly_data_split_2d)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(np.arange(1,b.size+1),b)\n",
        "print(f\"---------CASO 2----------\")\n",
        "print(f\"Numero di time series anomale: {np.count_nonzero(b == 1)} su {len(b)}\")\n",
        "print(f\"Numero di time series non anomale: {np.count_nonzero(b == 0)} su {len(b)}\")"
      ],
      "metadata": {
        "id": "8s6yCOaLpFO8",
        "outputId": "4d73f68d-58fc-472f-8dcc-638f8cb90df0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------CASO 1----------\n",
            "Numero di time series anomale: 4599 su 44550\n",
            "Numero di time series non anomale: 39951 su 44550\n",
            "---------CASO 2----------\n",
            "Numero di time series anomale: 20626 su 207900\n",
            "Numero di time series non anomale: 187274 su 207900\n"
          ]
        }
      ]
    }
  ]
}