{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AmQc5taV2xlq",
        "outputId": "b8b884c5-4eb7-43bd-8ce4-744b8214a281",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'project_CSD'...\n",
            "remote: Enumerating objects: 591, done.\u001b[K\n",
            "remote: Counting objects: 100% (419/419), done.\u001b[K\n",
            "remote: Compressing objects: 100% (319/319), done.\u001b[K\n",
            "remote: Total 591 (delta 127), reused 360 (delta 87), pack-reused 172\u001b[K\n",
            "Receiving objects: 100% (591/591), 45.48 MiB | 22.73 MiB/s, done.\n",
            "Resolving deltas: 100% (150/150), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://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@github.com/Meguazy/project_CSD.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd project_CSD/"
      ],
      "metadata": {
        "id": "QM_sb6Ah20hq",
        "outputId": "7a28ca0d-50eb-40ff-be09-c61535837e9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/project_CSD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Usare ogni volta che si inizia a lavorare per accertarsi che non ci siano\n",
        "#cambiamenti non sincronizzati\n",
        "\n",
        "!git pull"
      ],
      "metadata": {
        "id": "LNG_lS_t22hx",
        "outputId": "6de3184e-9942-4ec4-df53-80032bd0acb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import requests\n",
        "gcloud_token = !gcloud auth print-access-token\n",
        "gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
        "EMAIL = str(gcloud_tokeninfo['email'])\n",
        "\n",
        "!echo $EMAIL\n",
        "\n",
        "#Usare per fare commit atomici e frequenti.\n",
        "#Ricordiamoci di usare mettere sempre dei messaggi di commit chiari in modo da\n",
        "#poter rollbackare o cherry-pickare in caso di bisogno.\n",
        "\n",
        "!git config --global user.email $EMAIL\n",
        "\n",
        "!git add .\n",
        "!git commit -m \"\"\n",
        "!git push"
      ],
      "metadata": {
        "id": "rOXTaZTS23ED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph autoencoder using spektral, which is the tensorflow library for graph neural networks\n",
        "Sample"
      ],
      "metadata": {
        "id": "xYjQ0BzG1V-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "wLp7jKv20KYb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate a sample graph with anomalies\n",
        "def generate_sample_graph(num_nodes=10, anomalous_node=None):\n",
        "    adjacency_matrix = np.random.randint(2, size=(num_nodes, num_nodes))\n",
        "    adjacency_matrix = np.triu(adjacency_matrix, k=1) + np.triu(adjacency_matrix, k=1).T\n",
        "    np.fill_diagonal(adjacency_matrix, 0)\n",
        "\n",
        "    # Introduce anomaly by changing connections of a specific node\n",
        "    if anomalous_node is not None:\n",
        "        adjacency_matrix[anomalous_node] = np.random.randint(2, size=num_nodes)\n",
        "\n",
        "    return adjacency_matrix.astype(np.float32)"
      ],
      "metadata": {
        "id": "C-L_DvSB0Zeg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate a dataset with normal and anomalous graphs\n",
        "def generate_dataset(num_samples, num_nodes=10, anomalous_node=None):\n",
        "    X = [generate_sample_graph(num_nodes, anomalous_node) for _ in range(num_samples)]\n",
        "    return np.array(X)"
      ],
      "metadata": {
        "id": "Bll_Kh1u1rOs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graph Autoencoder Model with TensorFlow's Dense layers\n",
        "def create_graph_autoencoder(input_dim):\n",
        "    encoder_inputs = tf.keras.Input(shape=(input_dim, input_dim))\n",
        "    x = layers.Flatten()(encoder_inputs)\n",
        "    x = layers.Dense(32, activation='relu')(x)\n",
        "    x = layers.Dense(16, activation='relu')(x)\n",
        "    encoder_outputs = layers.Dense(8, activation='relu')(x)\n",
        "\n",
        "    decoder_inputs = tf.keras.Input(shape=(8,))\n",
        "    x = layers.Dense(16, activation='relu')(decoder_inputs)\n",
        "    x = layers.Dense(32, activation='relu')(x)\n",
        "    decoder_outputs = layers.Reshape((input_dim, input_dim))(layers.Dense(input_dim * input_dim, activation='sigmoid')(x))\n",
        "\n",
        "    encoder = tf.keras.Model(encoder_inputs, encoder_outputs, name='encoder')\n",
        "    decoder = tf.keras.Model(decoder_inputs, decoder_outputs, name='decoder')\n",
        "\n",
        "    autoencoder_inputs = tf.keras.Input(shape=(input_dim, input_dim))\n",
        "    autoencoder_outputs = decoder(encoder(autoencoder_inputs))\n",
        "\n",
        "    autoencoder = tf.keras.Model(autoencoder_inputs, autoencoder_outputs, name='autoencoder')\n",
        "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "    return autoencoder"
      ],
      "metadata": {
        "id": "e5Fj3-eS1tup"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "num_nodes = 10\n",
        "num_samples = 1000\n",
        "anomalous_node = 5  # Introduce anomaly in node 5"
      ],
      "metadata": {
        "id": "0j4ex63i1yF_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate dataset\n",
        "X = generate_dataset(num_samples, num_nodes, anomalous_node)"
      ],
      "metadata": {
        "id": "GomvktTZ115t"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create graph autoencoder\n",
        "autoencoder = create_graph_autoencoder(num_nodes)"
      ],
      "metadata": {
        "id": "Y2TojNHh179v"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Training Loop\n",
        "epochs = 50\n",
        "batch_size = 32\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    np.random.shuffle(X)\n",
        "\n",
        "    for i in range(0, len(X), batch_size):\n",
        "        batch = X[i:i+batch_size]\n",
        "        autoencoder.train_on_batch(batch, batch)"
      ],
      "metadata": {
        "id": "x4BsvwiW2ECD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on normal and anomalous samples\n",
        "normal_sample = generate_sample_graph(num_nodes)\n",
        "anomalous_sample = generate_sample_graph(num_nodes, anomalous_node)"
      ],
      "metadata": {
        "id": "7nydnDtY2fvb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_sample = np.expand_dims(normal_sample, axis=0)\n",
        "anomalous_sample = np.expand_dims(anomalous_sample, axis=0)"
      ],
      "metadata": {
        "id": "H2Dfe5C62hb-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on normal sample\n",
        "reconstructed_normal = autoencoder.predict(normal_sample)\n",
        "\n",
        "# Predict on anomalous sample\n",
        "reconstructed_anomalous = autoencoder.predict(anomalous_sample)\n",
        "\n",
        "# Calculate reconstruction errors\n",
        "error_normal = np.mean(np.abs(normal_sample - reconstructed_normal))\n",
        "error_anomalous = np.mean(np.abs(anomalous_sample - reconstructed_anomalous))\n",
        "\n",
        "print(\"Reconstruction error on normal sample:\", error_normal)\n",
        "print(\"Reconstruction error on anomalous sample:\", error_anomalous)"
      ],
      "metadata": {
        "id": "-OZ9KlBI2kID",
        "outputId": "f6910a04-beba-444d-ef76-0e5af4735c17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 306ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Reconstruction error on normal sample: 0.41946134\n",
            "Reconstruction error on anomalous sample: 0.35970485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph autoencoder using a Formal Approach\n",
        "https://www.youtube.com/watch?v=qA6U4nIK62E"
      ],
      "metadata": {
        "id": "ZPQnRhUe60zf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "id": "BS43IjzS7kJ1",
        "outputId": "6fc5cc93-7a98-4f60-cbed-f6c400624b7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os.path as osp\n",
        "import time\n",
        "\n",
        "import torch\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import GAE, VGAE, GCNConv\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--variational', action='store_true')\n",
        "parser.add_argument('--linear', action='store_true')\n",
        "parser.add_argument('--dataset', type=str, default='Cora',\n",
        "                    choices=['Cora', 'CiteSeer', 'PubMed'])\n",
        "parser.add_argument('--epochs', type=int, default=400)\n",
        "args = parser.parse_args()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.NormalizeFeatures(),\n",
        "    T.ToDevice(device),\n",
        "    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
        "                      split_labels=True, add_negative_train_samples=False),\n",
        "])\n",
        "path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', 'Planetoid')\n",
        "dataset = Planetoid(path, args.dataset, transform=transform)\n",
        "train_data, val_data, test_data = dataset[0]"
      ],
      "metadata": {
        "id": "EawHx1dk7QF5",
        "outputId": "cd7829b2-6082-4650-d362-561e14050277",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: colab_kernel_launcher.py [-h] [--variational] [--linear] [--dataset {Cora,CiteSeer,PubMed}]\n",
            "                                [--epochs EPOCHS]\n",
            "colab_kernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-56b3c4a6-f839-473c-8109-42e5d6a59717.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNEncoder(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
        "        self.conv2 = GCNConv(2 * out_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        return self.conv2(x, edge_index)\n",
        "\n",
        "\n",
        "class VariationalGCNEncoder(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
        "        self.conv_mu = GCNConv(2 * out_channels, out_channels)\n",
        "        self.conv_logstd = GCNConv(2 * out_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)\n",
        "\n",
        "\n",
        "class LinearEncoder(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = GCNConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        return self.conv(x, edge_index)\n",
        "\n",
        "\n",
        "class VariationalLinearEncoder(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv_mu = GCNConv(in_channels, out_channels)\n",
        "        self.conv_logstd = GCNConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)"
      ],
      "metadata": {
        "id": "hAMUQKJ07-km"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_channels, out_channels = dataset.num_features, 16\n",
        "\n",
        "if not args.variational and not args.linear:\n",
        "    model = GAE(GCNEncoder(in_channels, out_channels))\n",
        "elif not args.variational and args.linear:\n",
        "    model = GAE(LinearEncoder(in_channels, out_channels))\n",
        "elif args.variational and not args.linear:\n",
        "    model = VGAE(VariationalGCNEncoder(in_channels, out_channels))\n",
        "elif args.variational and args.linear:\n",
        "    model = VGAE(VariationalLinearEncoder(in_channels, out_channels))\n",
        "\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    z = model.encode(train_data.x, train_data.edge_index)\n",
        "    loss = model.recon_loss(z, train_data.pos_edge_label_index)\n",
        "    if args.variational:\n",
        "        loss = loss + (1 / train_data.num_nodes) * model.kl_loss()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(data):\n",
        "    model.eval()\n",
        "    z = model.encode(data.x, data.edge_index)\n",
        "    return model.test(z, data.pos_edge_label_index, data.neg_edge_label_index)\n",
        "\n",
        "\n",
        "times = []\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    start = time.time()\n",
        "    loss = train()\n",
        "    auc, ap = test(test_data)\n",
        "    print(f'Epoch: {epoch:03d}, AUC: {auc:.4f}, AP: {ap:.4f}')\n",
        "    times.append(time.time() - start)\n",
        "print(f\"Median time per epoch: {torch.tensor(times).median():.4f}s\")"
      ],
      "metadata": {
        "id": "fLtH9kkt8CB0",
        "outputId": "631d6bb8-083a-4607-f66e-e1910ed5e1fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-5c338e093fd4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariational\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGCNEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariational\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
          ]
        }
      ]
    }
  ]
}